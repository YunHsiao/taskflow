<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Cookbook &raquo; GPU Tasking (cudaFlow) | Taskflow QuickStart</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,400i,600,600i%7CSource+Code+Pro:400,400i,600" />
  <link rel="stylesheet" href="m-dark+documentation.compiled.css" />
  <link rel="icon" href="favicon.ico" type="image/x-icon" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="theme-color" content="#22272e" />
</head>
<body>
<header><nav id="navigation">
  <div class="m-container">
    <div class="m-row">
      <span id="m-navbar-brand" class="m-col-t-8 m-col-m-none m-left-m">
        <a href="https://taskflow.github.io"><img src="taskflow_logo.png" alt="" />Taskflow</a> <span class="m-breadcrumb">|</span> <a href="index.html" class="m-thin">QuickStart</a>
      </span>
      <div class="m-col-t-4 m-hide-m m-text-right m-nopadr">
        <a href="#search" class="m-doc-search-icon" title="Search" onclick="return showSearch()"><svg style="height: 0.9rem;" viewBox="0 0 16 16">
          <path id="m-doc-search-icon-path" d="m6 0c-3.31 0-6 2.69-6 6 0 3.31 2.69 6 6 6 1.49 0 2.85-0.541 3.89-1.44-0.0164 0.338 0.147 0.759 0.5 1.15l3.22 3.79c0.552 0.614 1.45 0.665 2 0.115 0.55-0.55 0.499-1.45-0.115-2l-3.79-3.22c-0.392-0.353-0.812-0.515-1.15-0.5 0.895-1.05 1.44-2.41 1.44-3.89 0-3.31-2.69-6-6-6zm0 1.56a4.44 4.44 0 0 1 4.44 4.44 4.44 4.44 0 0 1-4.44 4.44 4.44 4.44 0 0 1-4.44-4.44 4.44 4.44 0 0 1 4.44-4.44z"/>
        </svg></a>
        <a id="m-navbar-show" href="#navigation" title="Show navigation"></a>
        <a id="m-navbar-hide" href="#" title="Hide navigation"></a>
      </div>
      <div id="m-navbar-collapse" class="m-col-t-12 m-show-m m-col-m-none m-right-m">
        <div class="m-row">
          <ol class="m-col-t-6 m-col-m-none">
            <li><a href="pages.html">Handbook</a></li>
            <li><a href="namespaces.html">Namespaces</a></li>
          </ol>
          <ol class="m-col-t-6 m-col-m-none" start="3">
            <li><a href="annotated.html">Classes</a></li>
            <li><a href="files.html">Files</a></li>
            <li class="m-show-m"><a href="#search" class="m-doc-search-icon" title="Search" onclick="return showSearch()"><svg style="height: 0.9rem;" viewBox="0 0 16 16">
              <use href="#m-doc-search-icon-path" />
            </svg></a></li>
          </ol>
        </div>
      </div>
    </div>
  </div>
</nav></header>
<main><article>
  <div class="m-container m-container-inflatable">
    <div class="m-row">
      <div class="m-col-l-10 m-push-l-1">
        <h1>
          <span class="m-breadcrumb"><a href="Cookbook.html">Cookbook</a> &raquo;</span>
          GPU Tasking (cudaFlow)
        </h1>
        <div class="m-block m-default">
          <h3>Contents</h3>
          <ul>
            <li><a href="#C6_Create_a_cudaFlow">Create a cudaFlow</a></li>
            <li><a href="#C6_Compile_a_cudaFlow_program">Compile a cudaFlow Program</a></li>
            <li><a href="#C6_run_a_cudaflow_on_multiple_gpus">Run a cudaFlow on Multiple GPUs</a></li>
            <li><a href="#C6_GPUMemoryOperations">Access GPU Memory</a></li>
            <li><a href="#C6_Granularity">Study the Granularity</a></li>
            <li><a href="#C6_OffloadAndUpdateAcudaFlow">Offload and Update a cudaFlow</a></li>
            <li><a href="#C6_UsecudaFlowInAStandaloneEnvironment">Use cudaFlow in a Standalone Environment</a></li>
          </ul>
        </div>
<p>Modern scientific computing typically leverages GPU-powered parallel processing cores to speed up large-scale applications. This chapter discusses how to implement CPU-GPU heterogeneous tasking algorithms with <a href="https://developer.nvidia.com/cuda-zone">Nvidia CUDA</a>.</p><section id="C6_Create_a_cudaFlow"><h2><a href="#C6_Create_a_cudaFlow">Create a cudaFlow</a></h2><p>Taskflow enables concurrent CPU-GPU tasking by leveraging <a href="https://developer.nvidia.com/blog/cuda-graphs/">CUDA Graph</a>. The tasking interface is referred to as <em>cudaFlow</em>. A cudaFlow is a graph object of type <a href="classtf_1_1cudaFlow.html" class="m-doc">tf::<wbr />cudaFlow</a> created at runtime similar to dynamic tasking. It manages a task node in a taskflow and associates it with a CUDA Graph. To create a cudaFlow, emplace a callable with an argument of type <a href="classtf_1_1cudaFlow.html" class="m-doc">tf::<wbr />cudaFlow</a>. The following example implements the canonical saxpy (A·X Plus Y) task graph.</p><pre class="m-code"> <span class="mi">1</span><span class="o">:</span> <span class="err">#</span><span class="n">include</span> <span class="o">&lt;</span><span class="n">taskflow</span><span class="o">/</span><span class="n">cudaflow</span><span class="p">.</span><span class="n">hpp</span><span class="o">&gt;</span>
 <span class="mi">2</span><span class="o">:</span> 
 <span class="mi">3</span><span class="o">:</span> <span class="c1">// saxpy (single-precision A·X Plus Y) kernel</span>
 <span class="mi">4</span><span class="o">:</span> <span class="n">__global__</span> <span class="kt">void</span> <span class="n">saxpy</span><span class="p">(</span><span class="kt">int</span> <span class="n">n</span><span class="p">,</span> <span class="kt">float</span> <span class="n">a</span><span class="p">,</span> <span class="kt">float</span> <span class="o">*</span><span class="n">x</span><span class="p">,</span> <span class="kt">float</span> <span class="o">*</span><span class="n">y</span><span class="p">)</span> <span class="p">{</span>
 <span class="mi">5</span><span class="o">:</span>   <span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
 <span class="mi">6</span><span class="o">:</span>   <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">)</span> <span class="p">{</span>
 <span class="mi">7</span><span class="o">:</span>     <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span><span class="o">*</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
 <span class="mi">8</span><span class="o">:</span>   <span class="p">}</span>
 <span class="mi">9</span><span class="o">:</span> <span class="p">}</span>
<span class="mi">10</span><span class="o">:</span>
<span class="mi">11</span><span class="o">:</span> <span class="c1">// main function begins</span>
<span class="mi">12</span><span class="o">:</span> <span class="kt">int</span> <span class="n">main</span><span class="p">()</span> <span class="p">{</span>
<span class="mi">13</span><span class="o">:</span>
<span class="mi">14</span><span class="o">:</span>   <span class="n">tf</span><span class="o">::</span><span class="n">Taskflow</span> <span class="n">taskflow</span><span class="p">;</span>
<span class="mi">15</span><span class="o">:</span>   <span class="n">tf</span><span class="o">::</span><span class="n">Executor</span> <span class="n">executor</span><span class="p">;</span>
<span class="mi">16</span><span class="o">:</span>  
<span class="mi">17</span><span class="o">:</span>   <span class="k">const</span> <span class="kt">unsigned</span> <span class="n">N</span> <span class="o">=</span> <span class="mi">1</span><span class="o">&lt;&lt;</span><span class="mi">20</span><span class="p">;</span>                            <span class="c1">// size of the vector</span>
<span class="mi">18</span><span class="o">:</span>
<span class="mi">19</span><span class="o">:</span>   <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span> <span class="n">hx</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="mf">1.0f</span><span class="p">);</span>                      <span class="c1">// x vector at host</span>
<span class="mi">20</span><span class="o">:</span>   <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span> <span class="n">hy</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="mf">2.0f</span><span class="p">);</span>                      <span class="c1">// y vector at host</span>
<span class="mi">21</span><span class="o">:</span>
<span class="mi">22</span><span class="o">:</span>   <span class="kt">float</span> <span class="o">*</span><span class="n">dx</span><span class="p">{</span><span class="k">nullptr</span><span class="p">};</span>                                  <span class="c1">// x vector at device</span>
<span class="mi">23</span><span class="o">:</span>   <span class="kt">float</span> <span class="o">*</span><span class="n">dy</span><span class="p">{</span><span class="k">nullptr</span><span class="p">};</span>                                  <span class="c1">// y vector at device</span>
<span class="mi">24</span><span class="o">:</span>  
<span class="mi">25</span><span class="o">:</span>   <span class="n">tf</span><span class="o">::</span><span class="n">Task</span> <span class="n">allocate_x</span> <span class="o">=</span> <span class="n">taskflow</span><span class="p">.</span><span class="n">emplace</span><span class="p">(</span>
<span class="mi">26</span><span class="o">:</span>     <span class="p">[</span><span class="o">&amp;</span><span class="p">](){</span> <span class="n">cudaMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">dx</span><span class="p">,</span> <span class="n">N</span><span class="o">*</span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));}</span>
<span class="mi">27</span><span class="o">:</span>   <span class="p">).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;allocate_x&quot;</span><span class="p">);</span>
<span class="mi">28</span><span class="o">:</span>
<span class="mi">29</span><span class="o">:</span>   <span class="n">tf</span><span class="o">::</span><span class="n">Task</span> <span class="n">allocate_y</span> <span class="o">=</span> <span class="n">taskflow</span><span class="p">.</span><span class="n">emplace</span><span class="p">(</span>
<span class="mi">30</span><span class="o">:</span>     <span class="p">[</span><span class="o">&amp;</span><span class="p">](){</span> <span class="n">cudaMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">dy</span><span class="p">,</span> <span class="n">N</span><span class="o">*</span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));}</span>
<span class="mi">31</span><span class="o">:</span>   <span class="p">).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;allocate_y&quot;</span><span class="p">);</span>
<span class="mi">32</span><span class="o">:</span>
<span class="mi">33</span><span class="o">:</span>   <span class="n">tf</span><span class="o">::</span><span class="n">Task</span> <span class="n">cudaflow</span> <span class="o">=</span> <span class="n">taskflow</span><span class="p">.</span><span class="n">emplace</span><span class="p">([</span><span class="o">&amp;</span><span class="p">](</span><span class="n">tf</span><span class="o">::</span><span class="n">cudaFlow</span><span class="o">&amp;</span> <span class="n">cf</span><span class="p">)</span> <span class="p">{</span>
<span class="mi">34</span><span class="o">:</span>     <span class="c1">// create data transfer tasks</span>
<span class="mi">35</span><span class="o">:</span>     <span class="n">tf</span><span class="o">::</span><span class="n">cudaTask</span> <span class="n">h2d_x</span> <span class="o">=</span> <span class="n">cf</span><span class="p">.</span><span class="n">copy</span><span class="p">(</span><span class="n">dx</span><span class="p">,</span> <span class="n">hx</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span> <span class="n">N</span><span class="p">).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;h2d_x&quot;</span><span class="p">);</span> 
<span class="mi">36</span><span class="o">:</span>     <span class="n">tf</span><span class="o">::</span><span class="n">cudaTask</span> <span class="n">h2d_y</span> <span class="o">=</span> <span class="n">cf</span><span class="p">.</span><span class="n">copy</span><span class="p">(</span><span class="n">dy</span><span class="p">,</span> <span class="n">hy</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span> <span class="n">N</span><span class="p">).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;h2d_y&quot;</span><span class="p">);</span>
<span class="mi">37</span><span class="o">:</span>     <span class="n">tf</span><span class="o">::</span><span class="n">cudaTask</span> <span class="n">d2h_x</span> <span class="o">=</span> <span class="n">cf</span><span class="p">.</span><span class="n">copy</span><span class="p">(</span><span class="n">hx</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span> <span class="n">dx</span><span class="p">,</span> <span class="n">N</span><span class="p">).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;d2h_x&quot;</span><span class="p">);</span>
<span class="mi">38</span><span class="o">:</span>     <span class="n">tf</span><span class="o">::</span><span class="n">cudaTask</span> <span class="n">d2h_y</span> <span class="o">=</span> <span class="n">cf</span><span class="p">.</span><span class="n">copy</span><span class="p">(</span><span class="n">hy</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span> <span class="n">dy</span><span class="p">,</span> <span class="n">N</span><span class="p">).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;d2h_y&quot;</span><span class="p">);</span>
<span class="mi">39</span><span class="o">:</span>
<span class="mi">40</span><span class="o">:</span>     <span class="c1">// launch saxpy&lt;&lt;&lt;(N+255)/256, 256, 0&gt;&gt;&gt;(N, 2.0f, dx, dy)</span>
<span class="mi">41</span><span class="o">:</span>     <span class="n">tf</span><span class="o">::</span><span class="n">cudaTask</span> <span class="n">kernel</span> <span class="o">=</span> <span class="n">cf</span><span class="p">.</span><span class="n">kernel</span><span class="p">(</span>
<span class="mi">42</span><span class="o">:</span>       <span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">255</span><span class="p">)</span><span class="o">/</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">saxpy</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="mf">2.0f</span><span class="p">,</span> <span class="n">dx</span><span class="p">,</span> <span class="n">dy</span>
<span class="mi">43</span><span class="o">:</span>     <span class="p">).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;saxpy&quot;</span><span class="p">);</span>
<span class="mi">44</span><span class="o">:</span>
<span class="mi">45</span><span class="o">:</span>     <span class="n">kernel</span><span class="p">.</span><span class="n">succeed</span><span class="p">(</span><span class="n">h2d_x</span><span class="p">,</span> <span class="n">h2d_y</span><span class="p">)</span>
<span class="mi">46</span><span class="o">:</span>           <span class="p">.</span><span class="n">precede</span><span class="p">(</span><span class="n">d2h_x</span><span class="p">,</span> <span class="n">d2h_y</span><span class="p">);</span>
<span class="mi">48</span><span class="o">:</span>   <span class="p">}).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;saxpy&quot;</span><span class="p">);</span>
<span class="mi">49</span><span class="o">:</span>   <span class="n">cudaflow</span><span class="p">.</span><span class="n">succeed</span><span class="p">(</span><span class="n">allocate_x</span><span class="p">,</span> <span class="n">allocate_y</span><span class="p">);</span>  <span class="c1">// overlap memory alloc</span>
<span class="mi">50</span><span class="o">:</span>  
<span class="mi">51</span><span class="o">:</span>   <span class="n">executor</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">taskflow</span><span class="p">).</span><span class="n">wait</span><span class="p">();</span>
<span class="mi">52</span><span class="o">:</span>
<span class="mi">53</span><span class="o">:</span>   <span class="n">taskflow</span><span class="p">.</span><span class="n">dump</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="p">);</span>                  <span class="c1">// dump the taskflow</span>
<span class="mi">54</span><span class="o">:</span> <span class="p">}</span></pre><div class="m-graph"><svg style="width: 28.875rem; height: 14.250rem;" viewBox="0.00 0.00 461.67 228.00">
<g transform="scale(1 1) rotate(0) translate(4 224)">
<title>Taskflow</title>
<g class="m-cluster">
<title>cluster_p0x55b2191178a8</title>
<polygon points="8,-46 8,-176 445.6744,-176 445.6744,-46 8,-46"/>
<text text-anchor="middle" x="226.8372" y="-159.2">cudaFlow: saxpy</text>
</g>
<g class="m-node m-flat">
<title>p0x55b219117698</title>
<ellipse cx="284.8139" cy="-202" rx="59.1273" ry="18"/>
<text text-anchor="middle" x="284.8139" y="-197.2">allocate_x</text>
</g>
<g class="m-node">
<title>p0x55b2191178a8</title>
<polygon points="437.5732,-117 434.5732,-121 413.5732,-121 410.5732,-117 379.9788,-117 379.9788,-81 437.5732,-81 437.5732,-117"/>
<text text-anchor="middle" x="408.776" y="-94.2">saxpy</text>
</g>
<g class="m-edge">
<title>p0x55b219117698&#45;&gt;p0x55b2191178a8</title>
<path d="M327.2341,-189.4104C333.091,-186.7716 338.8229,-183.6541 343.8776,-180 363.8988,-165.5264 381.0892,-143.3234 392.7384,-125.8213"/>
<polygon points="395.8418,-127.4663 398.3107,-117.1631 389.9556,-123.6779 395.8418,-127.4663"/>
</g>
<g class="m-node m-flat">
<title>p0x55b2191177a0</title>
<ellipse cx="284.8139" cy="-18" rx="59.1273" ry="18"/>
<text text-anchor="middle" x="284.8139" y="-13.2">allocate_y</text>
</g>
<g class="m-edge">
<title>p0x55b2191177a0&#45;&gt;p0x55b2191178a8</title>
<path d="M323.8539,-31.6929C330.7263,-34.7063 337.6625,-38.161 343.8776,-42 358.1826,-50.8361 372.4065,-62.8666 383.8761,-73.5981"/>
<polygon points="381.7053,-76.3658 391.3437,-80.7648 386.5523,-71.3153 381.7053,-76.3658"/>
</g>
<g class="m-node m-flat">
<title>p0x7f2870401a50</title>
<ellipse cx="55.9767" cy="-126" rx="39.9534" ry="18"/>
<text text-anchor="middle" x="55.9767" y="-121.2">h2d_x</text>
</g>
<g class="m-node">
<title>p0x7f2870402bc0</title>
<polygon points="189.6491,-117 136.0546,-117 132.0546,-113 132.0546,-81 185.6491,-81 189.6491,-85 189.6491,-117"/>
<polyline points="185.6491,-113 132.0546,-113 "/>
<polyline points="185.6491,-113 185.6491,-81 "/>
<polyline points="185.6491,-113 189.6491,-117 "/>
<text text-anchor="middle" x="160.8518" y="-94.2">saxpy</text>
</g>
<g class="m-edge">
<title>p0x7f2870401a50&#45;&gt;p0x7f2870402bc0</title>
<path d="M90.8986,-117.0094C100.9091,-114.4322 111.8818,-111.6073 122.1075,-108.9747"/>
<polygon points="123.2093,-112.3053 132.0208,-106.4225 121.464,-105.5263 123.2093,-112.3053"/>
</g>
<g class="m-node m-flat">
<title>p0x7f2870402310</title>
<ellipse cx="284.8139" cy="-72" rx="39.9534" ry="18"/>
<text text-anchor="middle" x="284.8139" y="-67.2">d2h_x</text>
</g>
<g class="m-edge">
<title>p0x7f2870402bc0&#45;&gt;p0x7f2870402310</title>
<path d="M189.9154,-92.6697C204.3753,-89.5202 222.2025,-85.6373 238.487,-82.0904"/>
<polygon points="239.3571,-85.483 248.3831,-79.9349 237.8673,-78.6434 239.3571,-85.483"/>
</g>
<g class="m-node m-flat">
<title>p0x7f2870402780</title>
<ellipse cx="284.8139" cy="-126" rx="39.9534" ry="18"/>
<text text-anchor="middle" x="284.8139" y="-121.2">d2h_y</text>
</g>
<g class="m-edge">
<title>p0x7f2870402bc0&#45;&gt;p0x7f2870402780</title>
<path d="M189.9154,-105.3303C204.3753,-108.4798 222.2025,-112.3627 238.487,-115.9096"/>
<polygon points="237.8673,-119.3566 248.3831,-118.0651 239.3571,-112.517 237.8673,-119.3566"/>
</g>
<g class="m-node m-flat">
<title>p0x7f2870401eb0</title>
<ellipse cx="55.9767" cy="-72" rx="39.9534" ry="18"/>
<text text-anchor="middle" x="55.9767" y="-67.2">h2d_y</text>
</g>
<g class="m-edge">
<title>p0x7f2870401eb0&#45;&gt;p0x7f2870402bc0</title>
<path d="M90.8986,-80.9906C100.9091,-83.5678 111.8818,-86.3927 122.1075,-89.0253"/>
<polygon points="121.464,-92.4737 132.0208,-91.5775 123.2093,-85.6947 121.464,-92.4737"/>
</g>
<g class="m-edge">
<title>p0x7f2870402310&#45;&gt;p0x55b2191178a8</title>
<path d="M321.0021,-79.8821C336.3611,-83.2274 354.2919,-87.1329 369.9291,-90.5388"/>
<polygon points="369.3078,-93.9855 379.8236,-92.6939 370.7976,-87.1458 369.3078,-93.9855"/>
</g>
<g class="m-edge">
<title>p0x7f2870402780&#45;&gt;p0x55b2191178a8</title>
<path d="M321.0021,-118.1179C336.3611,-114.7726 354.2919,-110.8671 369.9291,-107.4612"/>
<polygon points="370.7976,-110.8542 379.8236,-105.3061 369.3078,-104.0145 370.7976,-110.8542"/>
</g>
</g>
</svg>
</div><p>Debrief:</p><ul><li>Lines 3-9 define a saxpy kernel using CUDA</li><li>Lines 19-20 declare two host vectors, <code>hx</code> and <code>hy</code></li><li>Lines 22-23 declare two device vector pointers, <code>dx</code> and <code>dy</code></li><li>Lines 25-31 declare two tasks to allocate memory for <code>dx</code> and <code>dy</code> on device, each of <code>N*sizeof(float)</code> bytes</li><li>Lines 33-48 create a cudaFlow to define a GPU task graph (two host-to-device data transfer tasks, one saxpy kernel task, and two device-to-host data transfer tasks)</li><li>Lines 49-53 define the task dependency between host tasks and the cudaFlow tasks and execute the taskflow</li></ul><p>Taskflow does not expend unnecessary efforts on kernel programming but focus on tasking CUDA operations with CPU work. We give users full privileges to craft a CUDA kernel that is commensurate with their domain knowledge. Users focus on developing high-performance kernels using a native CUDA toolkit, while leaving difficult task parallelism to Taskflow.</p><aside class="m-note m-warning"><h4>Attention</h4><p>You need to include <code><a href="cudaflow_8hpp.html" class="m-doc">taskflow/<wbr />cudaflow.hpp</a></code> in order to use <a href="classtf_1_1cudaFlow.html" class="m-doc">tf::<wbr />cudaFlow</a>.</p></aside></section><section id="C6_Compile_a_cudaFlow_program"><h2><a href="#C6_Compile_a_cudaFlow_program">Compile a cudaFlow Program</a></h2><p>Use <a href="https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html">nvcc</a> (at least v11.1) to compile a cudaFlow program:</p><pre class="m-console"><span class="go">~$ nvcc -std=c++17 my_cudaflow.cu -I path/to/include/taskflow -O2 -o my_cudaflow</span>
<span class="go">~$ ./my_cudaflow</span></pre><p>Please visit the page <a href="CompileTaskflowWithCUDA.html" class="m-doc">Compile Taskflow with CUDA</a> for more details.</p></section><section id="C6_run_a_cudaflow_on_multiple_gpus"><h2><a href="#C6_run_a_cudaflow_on_multiple_gpus">Run a cudaFlow on Multiple GPUs</a></h2><p>By default, a cudaFlow runs on the current GPU associated with the caller, which is typically <code>0</code>. You can run a cudaFlow on multiple GPUs by explicitly associating a cudaFlow or a kernel task with a CUDA device. A CUDA device is an integer number in the range of <code>[0, N)</code> representing the identifier of a GPU, where <code>N</code> is the number of GPUs in a system. The code below creates a cudaFlow that runs on GPU <code>0</code>.</p><pre class="m-code"><span class="n">taskflow</span><span class="p">.</span><span class="n">emplace_on</span><span class="p">([]</span> <span class="p">(</span><span class="n">tf</span><span class="o">::</span><span class="n">cudaFlow</span><span class="o">&amp;</span> <span class="n">cf</span><span class="p">)</span> <span class="p">{},</span> <span class="mi">0</span><span class="p">);</span>  <span class="c1">// place the cudaFlow on GPU 0</span></pre><p>You can place a kernel on a GPU explicitly through the method <a href="classtf_1_1cudaFlow.html#a4a839dbaa01237a440edfebe8faf4e5b" class="m-doc">tf::<wbr />cudaFlow::<wbr />kernel_on</a> that takes the GPU device identifier in the first argument.</p><pre class="m-code"> <span class="mi">1</span><span class="o">:</span> <span class="err">#</span><span class="n">include</span> <span class="o">&lt;</span><span class="n">taskflow</span><span class="o">/</span><span class="n">cudaflow</span><span class="p">.</span><span class="n">hpp</span><span class="o">&gt;</span>
 <span class="mi">2</span><span class="o">:</span> 
 <span class="mi">3</span><span class="o">:</span> <span class="c1">// saxpy (single-precision A·X Plus Y) kernel</span>
 <span class="mi">4</span><span class="o">:</span> <span class="n">__global__</span> <span class="kt">void</span> <span class="n">saxpy</span><span class="p">(</span><span class="kt">int</span> <span class="n">n</span><span class="p">,</span> <span class="kt">float</span> <span class="n">a</span><span class="p">,</span> <span class="kt">float</span> <span class="o">*</span><span class="n">x</span><span class="p">,</span> <span class="kt">float</span> <span class="o">*</span><span class="n">y</span><span class="p">,</span> <span class="kt">float</span> <span class="o">*</span><span class="n">z</span><span class="p">)</span> <span class="p">{</span>
 <span class="mi">5</span><span class="o">:</span>  <span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
 <span class="mi">6</span><span class="o">:</span>  <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">)</span> <span class="p">{</span>
 <span class="mi">7</span><span class="o">:</span>    <span class="n">z</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span><span class="o">*</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
 <span class="mi">8</span><span class="o">:</span>   <span class="p">}</span>
 <span class="mi">9</span><span class="o">:</span> <span class="p">}</span>
<span class="mi">10</span><span class="o">:</span>
<span class="mi">11</span><span class="o">:</span> <span class="kt">int</span> <span class="n">main</span><span class="p">()</span> <span class="p">{</span>
<span class="mi">12</span><span class="o">:</span>
<span class="mi">13</span><span class="o">:</span>   <span class="k">const</span> <span class="kt">unsigned</span> <span class="n">N</span> <span class="o">=</span> <span class="mi">1</span><span class="o">&lt;&lt;</span><span class="mi">20</span><span class="p">;</span>
<span class="mi">14</span><span class="o">:</span>   
<span class="mi">15</span><span class="o">:</span>   <span class="kt">float</span><span class="o">*</span> <span class="n">dx</span> <span class="p">{</span><span class="k">nullptr</span><span class="p">};</span>
<span class="mi">16</span><span class="o">:</span>   <span class="kt">float</span><span class="o">*</span> <span class="n">dy</span> <span class="p">{</span><span class="k">nullptr</span><span class="p">};</span>
<span class="mi">17</span><span class="o">:</span>   <span class="kt">float</span><span class="o">*</span> <span class="n">z1</span> <span class="p">{</span><span class="k">nullptr</span><span class="p">};</span>
<span class="mi">18</span><span class="o">:</span>   <span class="kt">float</span><span class="o">*</span> <span class="n">z2</span> <span class="p">{</span><span class="k">nullptr</span><span class="p">};</span>
<span class="mi">19</span><span class="o">:</span>  
<span class="mi">20</span><span class="o">:</span>   <span class="n">cudaMallocManaged</span><span class="p">(</span><span class="o">&amp;</span><span class="n">dx</span><span class="p">,</span> <span class="n">N</span><span class="o">*</span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>  <span class="c1">// create unified memory for x</span>
<span class="mi">21</span><span class="o">:</span>   <span class="n">cudaMallocManaged</span><span class="p">(</span><span class="o">&amp;</span><span class="n">dy</span><span class="p">,</span> <span class="n">N</span><span class="o">*</span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>  <span class="c1">// create unified memory for y</span>
<span class="mi">22</span><span class="o">:</span>   <span class="n">cudaMallocManaged</span><span class="p">(</span><span class="o">&amp;</span><span class="n">z1</span><span class="p">,</span> <span class="n">N</span><span class="o">*</span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>  <span class="c1">// result of saxpy task 1</span>
<span class="mi">23</span><span class="o">:</span>   <span class="n">cudaMallocManaged</span><span class="p">(</span><span class="o">&amp;</span><span class="n">z2</span><span class="p">,</span> <span class="n">N</span><span class="o">*</span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>  <span class="c1">// result of saxpy task 2</span>
<span class="mi">24</span><span class="o">:</span>  
<span class="mi">25</span><span class="o">:</span>   <span class="k">for</span><span class="p">(</span><span class="kt">unsigned</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span><span class="o">&lt;</span><span class="n">N</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
<span class="mi">26</span><span class="o">:</span>     <span class="n">dx</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
<span class="mi">27</span><span class="o">:</span>     <span class="n">dy</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
<span class="mi">28</span><span class="o">:</span>   <span class="p">}</span>
<span class="mi">29</span><span class="o">:</span>
<span class="mi">30</span><span class="o">:</span>   <span class="n">tf</span><span class="o">::</span><span class="n">Taskflow</span> <span class="n">taskflow</span><span class="p">;</span>
<span class="mi">31</span><span class="o">:</span>   <span class="n">tf</span><span class="o">::</span><span class="n">Executor</span> <span class="n">executor</span><span class="p">;</span>
<span class="mi">32</span><span class="o">:</span>  
<span class="mi">33</span><span class="o">:</span>   <span class="n">taskflow</span><span class="p">.</span><span class="n">emplace_on</span><span class="p">([</span><span class="o">&amp;</span><span class="p">](</span><span class="n">tf</span><span class="o">::</span><span class="n">cudaFlow</span><span class="o">&amp;</span> <span class="n">cf</span><span class="p">){</span>
<span class="mi">34</span><span class="o">:</span>     <span class="c1">// We create a cudaFlow on GPU 0. The scheduler will switch to </span>
<span class="mi">35</span><span class="o">:</span>     <span class="c1">// GPU context 0 when running this callable.</span>
<span class="mi">36</span><span class="o">:</span>
<span class="mi">37</span><span class="o">:</span>     <span class="c1">// launch the first saxpy kernel on GPU 1</span>
<span class="mi">38</span><span class="o">:</span>     <span class="n">cf</span><span class="p">.</span><span class="n">kernel_on</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">255</span><span class="p">)</span><span class="o">/</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">saxpy</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dx</span><span class="p">,</span> <span class="n">dy</span><span class="p">,</span> <span class="n">z1</span><span class="p">).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;1&quot;</span><span class="p">);</span>
<span class="mi">39</span><span class="o">:</span>
<span class="mi">40</span><span class="o">:</span>     <span class="c1">// launch the second saxpy kernel on GPU 3</span>
<span class="mi">41</span><span class="o">:</span>     <span class="n">cf</span><span class="p">.</span><span class="n">kernel_on</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">255</span><span class="p">)</span><span class="o">/</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">saxpy</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dx</span><span class="p">,</span> <span class="n">dy</span><span class="p">,</span> <span class="n">z2</span><span class="p">).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;3&quot;</span><span class="p">);</span>
<span class="mi">42</span><span class="o">:</span>   <span class="p">},</span> <span class="mi">0</span><span class="p">).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;cudaFlow on GPU 0&quot;</span><span class="p">);</span>
<span class="mi">43</span><span class="o">:</span>
<span class="mi">44</span><span class="o">:</span>   <span class="n">executor</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">taskflow</span><span class="p">).</span><span class="n">wait</span><span class="p">();</span>
<span class="mi">45</span><span class="o">:</span>
<span class="mi">46</span><span class="o">:</span>   <span class="n">cudaFree</span><span class="p">(</span><span class="n">dx</span><span class="p">);</span>
<span class="mi">47</span><span class="o">:</span>   <span class="n">cudaFree</span><span class="p">(</span><span class="n">dy</span><span class="p">);</span>
<span class="mi">48</span><span class="o">:</span>  
<span class="mi">49</span><span class="o">:</span>   <span class="c1">// verify the solution; max_error should be zero</span>
<span class="mi">50</span><span class="o">:</span>   <span class="kt">float</span> <span class="n">max_error</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
<span class="mi">51</span><span class="o">:</span>   <span class="k">for</span> <span class="p">(</span><span class="kt">size_t</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">N</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
<span class="mi">52</span><span class="o">:</span>     <span class="n">max_error</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">max</span><span class="p">(</span><span class="n">max_error</span><span class="p">,</span> <span class="n">abs</span><span class="p">(</span><span class="n">z1</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="mi">-4</span><span class="p">));</span>
<span class="mi">53</span><span class="o">:</span>     <span class="n">max_error</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">max</span><span class="p">(</span><span class="n">max_error</span><span class="p">,</span> <span class="n">abs</span><span class="p">(</span><span class="n">z2</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="mi">-4</span><span class="p">));</span>
<span class="mi">54</span><span class="o">:</span>   <span class="p">}</span>
<span class="mi">55</span><span class="o">:</span>   <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">&quot;saxpy finished with max error: &quot;</span> <span class="o">&lt;&lt;</span> <span class="n">max_error</span> <span class="o">&lt;&lt;</span> <span class="sc">&#39;\n&#39;</span><span class="p">;</span>
<span class="mi">56</span><span class="o">:</span> <span class="p">}</span></pre><p>Debrief:</p><ul><li>Lines 3-9 define a CUDA saxpy kernel that stores the result to <code>z</code></li><li>Lines 15-23 declare four unified memory blocks accessible from any processor</li><li>Lines 25-28 initialize <code>dx</code> and <code>dy</code> blocks by CPU</li><li>Lines 33-42 create a cudaFlow task on GPU <code>0</code> using <a href="classtf_1_1FlowBuilder.html#afdf47fd1a358fb64f8c1b89e2a393169" class="m-doc">tf::<wbr />Taskflow::<wbr />emplace_on</a></li><li>Lines 37-38 create a kernel task to launch the first saxpy on GPU <code>1</code> and store the result in <code>z1</code></li><li>Lines 40-41 create a kernel task to launch the second saxpy on GPU <code>3</code> and store the result in <code>z2</code></li><li>Lines 44-55 run the taskflow and verify the result (<code>max_error</code> should be zero)</li></ul><p>Running the program gives the following <a href="https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html">nvidia-smi</a> snapshot in a system of 4 GPUs:</p><pre class="m-console"><span class="go">+-----------------------------------------------------------------------------+</span>
<span class="go">| Processes:                                                       GPU Memory |</span>
<span class="go">|  GPU       PID   Type   Process name                             Usage      |</span>
<span class="go">|=============================================================================|</span>
<span class="go">|    0     53869      C   ./a.out                                      153MiB |</span>
<span class="go">|    1     53869      C   ./a.out                                      155MiB |</span>
<span class="go">|    3     53869      C   ./a.out                                      155MiB |</span>
<span class="go">+-----------------------------------------------------------------------------+</span></pre><aside class="m-note m-warning"><h4>Attention</h4><p><a href="classtf_1_1FlowBuilder.html#afdf47fd1a358fb64f8c1b89e2a393169" class="m-doc">tf::<wbr />Taskflow::<wbr />emplace_on</a> allows you to place a cudaFlow on a particular GPU device, but it is your responsibility to ensure correct memory access. For example, you may not allocate a memory block on GPU <code>2</code> using <code>cudaMalloc</code> and access it from a kernel on GPU <code>1</code>.</p></aside><p>An easy practice is to allocate <em>unified shared memory</em> using <code>cudaMallocManaged</code> and let the CUDA runtime perform automatic memory migration between processors (as demonstrated in the code example above).</p><p>As the same example, you may create two cudaFlows for the two kernels on two GPUs, respectively. The overhead of creating a kernel on the same device as a cudaFlow is much less than the different one.</p><pre class="m-code"><span class="n">tf</span><span class="o">::</span><span class="n">Task</span> <span class="n">cudaFlow_on_gpu1</span> <span class="o">=</span> <span class="n">taskflow</span><span class="p">.</span><span class="n">emplace_on</span><span class="p">([</span><span class="o">&amp;</span><span class="p">](</span><span class="n">tf</span><span class="o">::</span><span class="n">cudaFlow</span><span class="o">&amp;</span> <span class="n">cf</span><span class="p">){</span>
  <span class="n">cf</span><span class="p">.</span><span class="n">kernel</span><span class="p">((</span><span class="n">N</span><span class="o">+</span><span class="mi">255</span><span class="p">)</span><span class="o">/</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">saxpy</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dx</span><span class="p">,</span> <span class="n">dy</span><span class="p">,</span> <span class="n">z1</span><span class="p">);</span>
<span class="p">},</span> <span class="mi">1</span><span class="p">);</span>

<span class="n">tf</span><span class="o">::</span><span class="n">Task</span> <span class="n">cudaFlow_on_gpu3</span> <span class="o">=</span> <span class="n">taskflow</span><span class="p">.</span><span class="n">emplace_on</span><span class="p">([</span><span class="o">&amp;</span><span class="p">](</span><span class="n">tf</span><span class="o">::</span><span class="n">cudaFlow</span><span class="o">&amp;</span> <span class="n">cf</span><span class="p">){</span>
  <span class="n">cf</span><span class="p">.</span><span class="n">kernel</span><span class="p">((</span><span class="n">N</span><span class="o">+</span><span class="mi">255</span><span class="p">)</span><span class="o">/</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">saxpy</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dx</span><span class="p">,</span> <span class="n">dy</span><span class="p">,</span> <span class="n">z2</span><span class="p">);</span>
<span class="p">},</span> <span class="mi">3</span><span class="p">);</span></pre></section><section id="C6_GPUMemoryOperations"><h2><a href="#C6_GPUMemoryOperations">Access GPU Memory</a></h2><p><a href="classtf_1_1cudaFlow.html" class="m-doc">tf::<wbr />cudaFlow</a> provides a set of methods for users to manipulate device memory data. There are two categories, raw data and typed data. Raw data operations are methods with prefix <code>mem</code>, such as <code>memcpy</code> and <code>memset</code>, that take action on GPU memory area in <em>bytes</em>. Typed data operations such as <code>copy</code>, <code>fill</code>, and <code>zero</code>, take <em>logical count</em> of elements. For instance, the following three methods have the same result of zeroing <code>sizeof(int)*count</code> bytes of the device memory area pointed to by <code>target</code>.</p><pre class="m-code"><span class="kt">int</span><span class="o">*</span> <span class="n">target</span><span class="p">;</span>
<span class="n">cudaMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">target</span><span class="p">,</span> <span class="n">count</span><span class="o">*</span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">));</span>

<span class="n">taskflow</span><span class="p">.</span><span class="n">emplace</span><span class="p">([</span><span class="o">&amp;</span><span class="p">](</span><span class="n">tf</span><span class="o">::</span><span class="n">cudaFlow</span><span class="o">&amp;</span> <span class="n">cf</span><span class="p">){</span>
  <span class="n">tf</span><span class="o">::</span><span class="n">cudaTask</span> <span class="n">memset_target</span> <span class="o">=</span> <span class="n">cf</span><span class="p">.</span><span class="n">memset</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">)</span> <span class="o">*</span> <span class="n">count</span><span class="p">);</span>
  <span class="n">tf</span><span class="o">::</span><span class="n">cudaTask</span> <span class="n">same_as_above</span> <span class="o">=</span> <span class="n">cf</span><span class="p">.</span><span class="n">fill</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">count</span><span class="p">);</span>
  <span class="n">tf</span><span class="o">::</span><span class="n">cudaTask</span> <span class="n">same_as_above_again</span> <span class="o">=</span> <span class="n">cf</span><span class="p">.</span><span class="n">zero</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">count</span><span class="p">);</span>
<span class="p">});</span></pre><p>The method <a href="classtf_1_1cudaFlow.html#a21d4447bc834f4d3e1bb4772c850d090" class="m-doc">cudaFlow::<wbr />fill</a> is a more powerful version of <a href="classtf_1_1cudaFlow.html#a079ca65da35301e5aafd45878a19e9d2" class="m-doc">cudaFlow::<wbr />memset</a>. It can fill a memory area with any value of type <code>T</code>, given that <code>sizeof(T)</code> is 1, 2, or 4 bytes. For example, the following code sets each element in the array <code>target</code> to 1234.</p><pre class="m-code"><span class="n">taskflow</span><span class="p">.</span><span class="n">emplace</span><span class="p">([</span><span class="o">&amp;</span><span class="p">](</span><span class="n">tf</span><span class="o">::</span><span class="n">cudaFlow</span><span class="o">&amp;</span> <span class="n">cf</span><span class="p">){</span> <span class="n">cf</span><span class="p">.</span><span class="n">fill</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="mi">1234</span><span class="p">,</span> <span class="n">count</span><span class="p">);</span> <span class="p">});</span></pre><p>Similar concept applies to <a href="classtf_1_1cudaFlow.html#ad37637606f0643f360e9eda1f9a6e559" class="m-doc">cudaFlow::<wbr />memcpy</a> and <a href="classtf_1_1cudaFlow.html#af03e04771b655f9e629eb4c22e19b19f" class="m-doc">cudaFlow::<wbr />copy</a> as well.</p><pre class="m-code"><span class="n">taskflow</span><span class="p">.</span><span class="n">emplace</span><span class="p">([</span><span class="o">&amp;</span><span class="p">](</span><span class="n">tf</span><span class="o">::</span><span class="n">cudaFlow</span><span class="o">&amp;</span> <span class="n">cf</span><span class="p">){</span>
  <span class="n">tf</span><span class="o">::</span><span class="n">cudaTask</span> <span class="n">memcpy_target</span> <span class="o">=</span> <span class="n">cf</span><span class="p">.</span><span class="n">memcpy</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">source</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">)</span> <span class="o">*</span> <span class="n">count</span><span class="p">);</span>
  <span class="n">tf</span><span class="o">::</span><span class="n">cudaTask</span> <span class="n">same_as_above</span> <span class="o">=</span> <span class="n">cf</span><span class="p">.</span><span class="n">copy</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">source</span><span class="p">,</span> <span class="n">count</span><span class="p">);</span>
<span class="p">});</span></pre></section><section id="C6_Granularity"><h2><a href="#C6_Granularity">Study the Granularity</a></h2><p>Creating a cudaFlow has certain overhead, which means fined-grained tasking such as one GPU operation per cudaFlow may not give you any performance gain. You should aggregate as many GPU operations as possible in a cudaFlow to launch the entire graph once instead of separate calls. For example, the following code creates the saxpy task graph at a very fine-grained level using one cudaFlow per GPU operation.</p><pre class="m-code"><span class="n">tf</span><span class="o">::</span><span class="n">Task</span> <span class="n">h2d_x</span> <span class="o">=</span> <span class="n">taskflow</span><span class="p">.</span><span class="n">emplace</span><span class="p">([</span><span class="o">&amp;</span><span class="p">](</span><span class="n">tf</span><span class="o">::</span><span class="n">cudaFlow</span><span class="o">&amp;</span> <span class="n">cf</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">cf</span><span class="p">.</span><span class="n">copy</span><span class="p">(</span><span class="n">dx</span><span class="p">,</span> <span class="n">hx</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span> <span class="n">N</span><span class="p">).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;h2d_x&quot;</span><span class="p">);</span>
<span class="p">}).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;h2d_x&quot;</span><span class="p">);</span>  <span class="c1">// creates the 1st cudaFlow</span>

<span class="n">tf</span><span class="o">::</span><span class="n">Task</span> <span class="n">h2d_y</span> <span class="o">=</span> <span class="n">taskflow</span><span class="p">.</span><span class="n">emplace</span><span class="p">([</span><span class="o">&amp;</span><span class="p">](</span><span class="n">tf</span><span class="o">::</span><span class="n">cudaFlow</span><span class="o">&amp;</span> <span class="n">cf</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">cf</span><span class="p">.</span><span class="n">copy</span><span class="p">(</span><span class="n">dy</span><span class="p">,</span> <span class="n">hy</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span> <span class="n">N</span><span class="p">).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;h2d_y&quot;</span><span class="p">);</span>
<span class="p">}).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;h2d_y&quot;</span><span class="p">);</span>  <span class="c1">// creates the 2nd cudaFlow </span>

<span class="n">tf</span><span class="o">::</span><span class="n">Task</span> <span class="n">d2h_x</span> <span class="o">=</span> <span class="n">taskflow</span><span class="p">.</span><span class="n">emplace</span><span class="p">([</span><span class="o">&amp;</span><span class="p">](</span><span class="n">tf</span><span class="o">::</span><span class="n">cudaFlow</span><span class="o">&amp;</span> <span class="n">cf</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">cf</span><span class="p">.</span><span class="n">copy</span><span class="p">(</span><span class="n">hx</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span> <span class="n">dx</span><span class="p">,</span> <span class="n">N</span><span class="p">).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;d2h_x&quot;</span><span class="p">);</span>
<span class="p">}).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;d2h_x&quot;</span><span class="p">);</span>  <span class="c1">// creates the 3rd cudaFlow</span>

<span class="n">tf</span><span class="o">::</span><span class="n">Task</span> <span class="n">d2h_y</span> <span class="o">=</span> <span class="n">taskflow</span><span class="p">.</span><span class="n">emplace</span><span class="p">([</span><span class="o">&amp;</span><span class="p">](</span><span class="n">tf</span><span class="o">::</span><span class="n">cudaFlow</span><span class="o">&amp;</span> <span class="n">cf</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">cf</span><span class="p">.</span><span class="n">copy</span><span class="p">(</span><span class="n">hy</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span> <span class="n">dy</span><span class="p">,</span> <span class="n">N</span><span class="p">).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;d2h_y&quot;</span><span class="p">);</span>
<span class="p">}).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;d2h_y&quot;</span><span class="p">);</span>  <span class="c1">// creates the 4th cudaFlow</span>

<span class="n">tf</span><span class="o">::</span><span class="n">Task</span> <span class="n">kernel</span> <span class="o">=</span> <span class="n">taskflow</span><span class="p">.</span><span class="n">emplace</span><span class="p">([</span><span class="o">&amp;</span><span class="p">](</span><span class="n">tf</span><span class="o">::</span><span class="n">cudaFlow</span><span class="o">&amp;</span> <span class="n">cf</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">cf</span><span class="p">.</span><span class="n">kernel</span><span class="p">((</span><span class="n">N</span><span class="o">+</span><span class="mi">255</span><span class="p">)</span><span class="o">/</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">saxpy</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="mf">2.0f</span><span class="p">,</span> <span class="n">dx</span><span class="p">,</span> <span class="n">dy</span><span class="p">).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;saxpy&quot;</span><span class="p">);</span>
<span class="p">}).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;kernel&quot;</span><span class="p">);</span> <span class="c1">// creates the 5th cudaFlow</span>

<span class="n">kernel</span><span class="p">.</span><span class="n">succeed</span><span class="p">(</span><span class="n">h2d_x</span><span class="p">,</span> <span class="n">h2d_y</span><span class="p">)</span>
      <span class="p">.</span><span class="n">precede</span><span class="p">(</span><span class="n">d2h_x</span><span class="p">,</span> <span class="n">d2h_y</span><span class="p">);</span></pre><div class="m-graph"><svg style="width: 37.000rem; height: 20.750rem;" viewBox="0.00 0.00 592.00 332.00">
<g transform="scale(1 1) rotate(0) translate(4 328)">
<title>Taskflow</title>
<g class="m-cluster">
<title>cluster_p0x21987b0</title>
<polygon points="440,-164 440,-316 576,-316 576,-164 440,-164"/>
<text text-anchor="middle" x="508" y="-299.2">cudaFlow: h2d_x</text>
</g>
<g class="m-cluster">
<title>cluster_p0x2198870</title>
<polygon points="296,-164 296,-316 432,-316 432,-164 296,-164"/>
<text text-anchor="middle" x="364" y="-299.2">cudaFlow: h2d_y</text>
</g>
<g class="m-cluster">
<title>cluster_p0x2198930</title>
<polygon points="8,-8 8,-156 144,-156 144,-8 8,-8"/>
<text text-anchor="middle" x="76" y="-139.2">cudaFlow: d2h_x</text>
</g>
<g class="m-cluster">
<title>cluster_p0x21989f0</title>
<polygon points="296,-8 296,-156 432,-156 432,-8 296,-8"/>
<text text-anchor="middle" x="364" y="-139.2">cudaFlow: d2h_y</text>
</g>
<g class="m-cluster">
<title>cluster_p0x2198ab0</title>
<polygon points="152,-80 152,-240 288,-240 288,-80 152,-80"/>
<text text-anchor="middle" x="220" y="-223.2">cudaFlow: kernel</text>
</g>
<g class="m-node">
<title>p0x21987b0</title>
<polygon points="512.5951,-208 509.5951,-212 488.5951,-212 485.5951,-208 453.4049,-208 453.4049,-172 512.5951,-172 512.5951,-208"/>
<text text-anchor="middle" x="483" y="-185.2">h2d_x</text>
</g>
<g class="m-node">
<title>p0x2198ab0</title>
<polygon points="279.5796,-124 276.5796,-128 255.5796,-128 252.5796,-124 220.4204,-124 220.4204,-88 279.5796,-88 279.5796,-124"/>
<text text-anchor="middle" x="250" y="-101.2">kernel</text>
</g>
<g class="m-edge">
<title>p0x21987b0&#45;&gt;p0x2198ab0</title>
<path d="M455.0611,-171.8926C448.9923,-168.7275 442.4518,-165.858 436,-164 405.2023,-155.1308 320.6634,-170.3378 292,-156 281.4428,-150.7192 272.5253,-141.4623 265.6602,-132.3376"/>
<polygon points="268.5253,-130.3271 259.9444,-124.1127 262.777,-134.3218 268.5253,-130.3271"/>
</g>
<g class="m-node">
<title>p0x2198930</title>
<polygon points="130.5951,-52 127.5951,-56 106.5951,-56 103.5951,-52 71.4049,-52 71.4049,-16 130.5951,-16 130.5951,-52"/>
<text text-anchor="middle" x="101" y="-29.2">d2h_x</text>
</g>
<g class="m-edge">
<title>p0x2198ab0&#45;&gt;p0x2198930</title>
<path d="M220.2057,-91.6028C197.1623,-80.4677 165.0638,-64.957 139.9795,-52.8357"/>
<polygon points="141.2693,-49.5718 130.7426,-48.3723 138.2237,-55.8746 141.2693,-49.5718"/>
</g>
<g class="m-node">
<title>p0x21989f0</title>
<polygon points="368.5951,-52 365.5951,-56 344.5951,-56 341.5951,-52 309.4049,-52 309.4049,-16 368.5951,-16 368.5951,-52"/>
<text text-anchor="middle" x="339" y="-29.2">d2h_y</text>
</g>
<g class="m-edge">
<title>p0x2198ab0&#45;&gt;p0x21989f0</title>
<path d="M272.4585,-87.8314C283.4205,-78.9632 296.7699,-68.1637 308.6265,-58.5718"/>
<polygon points="310.9755,-61.1734 316.5487,-52.1628 306.5729,-55.7313 310.9755,-61.1734"/>
</g>
<g class="m-node m-flat">
<title>p0x7fe390000e60</title>
<ellipse cx="488" cy="-266" rx="39.9534" ry="18"/>
<text text-anchor="middle" x="488" y="-261.2">h2d_x</text>
</g>
<g class="m-edge">
<title>p0x7fe390000e60&#45;&gt;p0x21987b0</title>
<path d="M486.8151,-247.9891C486.234,-239.1566 485.5204,-228.3099 484.8682,-218.3965"/>
<polygon points="488.3428,-217.8937 484.1938,-208.145 481.3579,-218.3533 488.3428,-217.8937"/>
</g>
<g class="m-node">
<title>p0x2198870</title>
<polygon points="368.5951,-208 365.5951,-212 344.5951,-212 341.5951,-208 309.4049,-208 309.4049,-172 368.5951,-172 368.5951,-208"/>
<text text-anchor="middle" x="339" y="-185.2">h2d_y</text>
</g>
<g class="m-edge">
<title>p0x2198870&#45;&gt;p0x2198ab0</title>
<path d="M311.2661,-171.6662C304.7016,-166.865 297.8994,-161.4871 292,-156 284.1554,-148.7038 276.3793,-139.981 269.6899,-131.879"/>
<polygon points="272.3954,-129.6583 263.4005,-124.0599 266.9409,-134.0457 272.3954,-129.6583"/>
</g>
<g class="m-node m-flat">
<title>p0x7fe390001890</title>
<ellipse cx="344" cy="-266" rx="39.9534" ry="18"/>
<text text-anchor="middle" x="344" y="-261.2">h2d_y</text>
</g>
<g class="m-edge">
<title>p0x7fe390001890&#45;&gt;p0x2198870</title>
<path d="M342.8151,-247.9891C342.234,-239.1566 341.5204,-228.3099 340.8682,-218.3965"/>
<polygon points="344.3428,-217.8937 340.1938,-208.145 337.3579,-218.3533 344.3428,-217.8937"/>
</g>
<g class="m-node m-flat">
<title>p0x7fe39000b790</title>
<ellipse cx="96" cy="-106" rx="39.9534" ry="18"/>
<text text-anchor="middle" x="96" y="-101.2">d2h_x</text>
</g>
<g class="m-edge">
<title>p0x7fe39000b790&#45;&gt;p0x2198930</title>
<path d="M97.2617,-87.8314C97.7965,-80.131 98.4323,-70.9743 99.0266,-62.4166"/>
<polygon points="102.52,-62.6317 99.7213,-52.4133 95.5368,-62.1467 102.52,-62.6317"/>
</g>
<g class="m-node m-flat">
<title>p0x7fe3900017e0</title>
<ellipse cx="344" cy="-106" rx="39.9534" ry="18"/>
<text text-anchor="middle" x="344" y="-101.2">d2h_y</text>
</g>
<g class="m-edge">
<title>p0x7fe3900017e0&#45;&gt;p0x21989f0</title>
<path d="M342.7383,-87.8314C342.2035,-80.131 341.5677,-70.9743 340.9734,-62.4166"/>
<polygon points="344.4632,-62.1467 340.2787,-52.4133 337.48,-62.6317 344.4632,-62.1467"/>
</g>
<g class="m-node">
<title>p0x7fe390002000</title>
<polygon points="278.7972,-208 225.2028,-208 221.2028,-204 221.2028,-172 274.7972,-172 278.7972,-176 278.7972,-208"/>
<polyline points="274.7972,-204 221.2028,-204 "/>
<polyline points="274.7972,-204 274.7972,-172 "/>
<polyline points="274.7972,-204 278.7972,-208 "/>
<text text-anchor="middle" x="250" y="-185.2">saxpy</text>
</g>
<g class="m-edge">
<title>p0x7fe390002000&#45;&gt;p0x2198ab0</title>
<path d="M250,-171.7733C250,-160.8758 250,-146.7946 250,-134.4587"/>
<polygon points="253.5001,-134.1911 250,-124.1912 246.5001,-134.1912 253.5001,-134.1911"/>
</g>
</g>
</svg>
</div><p>The following code aggregates the five GPU operations using one cudaFlow and achieves better performance.</p><pre class="m-code"><span class="n">tf</span><span class="o">::</span><span class="n">Task</span> <span class="n">cudaflow</span> <span class="o">=</span> <span class="n">taskflow</span><span class="p">.</span><span class="n">emplace</span><span class="p">([</span><span class="o">&amp;</span><span class="p">](</span><span class="n">tf</span><span class="o">::</span><span class="n">cudaFlow</span><span class="o">&amp;</span> <span class="n">cf</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">tf</span><span class="o">::</span><span class="n">cudaTask</span> <span class="n">h2d_x</span> <span class="o">=</span> <span class="n">cf</span><span class="p">.</span><span class="n">copy</span><span class="p">(</span><span class="n">dx</span><span class="p">,</span> <span class="n">hx</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span> <span class="n">N</span><span class="p">).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;h2d_x&quot;</span><span class="p">);</span>
  <span class="n">tf</span><span class="o">::</span><span class="n">cudaTask</span> <span class="n">h2d_y</span> <span class="o">=</span> <span class="n">cf</span><span class="p">.</span><span class="n">copy</span><span class="p">(</span><span class="n">dy</span><span class="p">,</span> <span class="n">hy</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span> <span class="n">N</span><span class="p">).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;h2d_y&quot;</span><span class="p">);</span>
  <span class="n">tf</span><span class="o">::</span><span class="n">cudaTask</span> <span class="n">d2h_x</span> <span class="o">=</span> <span class="n">cf</span><span class="p">.</span><span class="n">copy</span><span class="p">(</span><span class="n">hx</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span> <span class="n">dx</span><span class="p">,</span> <span class="n">N</span><span class="p">).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;d2h_x&quot;</span><span class="p">);</span>
  <span class="n">tf</span><span class="o">::</span><span class="n">cudaTask</span> <span class="n">d2h_y</span> <span class="o">=</span> <span class="n">cf</span><span class="p">.</span><span class="n">copy</span><span class="p">(</span><span class="n">hy</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span> <span class="n">dy</span><span class="p">,</span> <span class="n">N</span><span class="p">).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;d2h_y&quot;</span><span class="p">);</span>
  <span class="n">tf</span><span class="o">::</span><span class="n">cudaTask</span> <span class="n">saxpy</span> <span class="o">=</span> <span class="n">cf</span><span class="p">.</span><span class="n">kernel</span><span class="p">((</span><span class="n">N</span><span class="o">+</span><span class="mi">255</span><span class="p">)</span><span class="o">/</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">saxpy</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="mf">2.0f</span><span class="p">,</span> <span class="n">dx</span><span class="p">,</span> <span class="n">dy</span><span class="p">)</span>
                         <span class="p">.</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;saxpy&quot;</span><span class="p">);</span>
  <span class="n">saxpy</span><span class="p">.</span><span class="n">succeed</span><span class="p">(</span><span class="n">h2d_x</span><span class="p">,</span> <span class="n">h2d_y</span><span class="p">)</span>
       <span class="p">.</span><span class="n">precede</span><span class="p">(</span><span class="n">d2h_x</span><span class="p">,</span> <span class="n">d2h_y</span><span class="p">);</span>
<span class="p">}).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;saxpy&quot;</span><span class="p">);</span>  <span class="c1">// creates one cudaFlow</span></pre><div class="m-graph"><svg style="width: 18.625rem; height: 6.125rem;" viewBox="0.00 0.00 297.70 98.00">
<g transform="scale(1 1) rotate(0) translate(4 94)">
<title>Taskflow</title>
<g class="m-node m-flat">
<title>p0x7f2870401a50</title>
<ellipse cx="39.9767" cy="-72" rx="39.9534" ry="18"/>
<text text-anchor="middle" x="39.9767" y="-67.2">h2d_x</text>
</g>
<g class="m-node">
<title>p0x7f2870402bc0</title>
<polygon points="173.6491,-63 120.0546,-63 116.0546,-59 116.0546,-27 169.6491,-27 173.6491,-31 173.6491,-63"/>
<polyline points="169.6491,-59 116.0546,-59 "/>
<polyline points="169.6491,-59 169.6491,-27 "/>
<polyline points="169.6491,-59 173.6491,-63 "/>
<text text-anchor="middle" x="144.8518" y="-40.2">saxpy</text>
</g>
<g class="m-edge">
<title>p0x7f2870401a50&#45;&gt;p0x7f2870402bc0</title>
<path d="M74.8986,-63.0094C84.9091,-60.4322 95.8818,-57.6073 106.1075,-54.9747"/>
<polygon points="107.2093,-58.3053 116.0208,-52.4225 105.464,-51.5263 107.2093,-58.3053"/>
</g>
<g class="m-node m-flat">
<title>p0x7f2870402310</title>
<ellipse cx="249.727" cy="-72" rx="39.9534" ry="18"/>
<text text-anchor="middle" x="249.727" y="-67.2">d2h_x</text>
</g>
<g class="m-edge">
<title>p0x7f2870402bc0&#45;&gt;p0x7f2870402310</title>
<path d="M173.7871,-52.4493C183.4357,-54.9334 194.4229,-57.762 204.9844,-60.4811"/>
<polygon points="204.3655,-63.9358 214.9223,-63.0396 206.1107,-57.1568 204.3655,-63.9358"/>
</g>
<g class="m-node m-flat">
<title>p0x7f2870402780</title>
<ellipse cx="249.727" cy="-18" rx="39.9534" ry="18"/>
<text text-anchor="middle" x="249.727" y="-13.2">d2h_y</text>
</g>
<g class="m-edge">
<title>p0x7f2870402bc0&#45;&gt;p0x7f2870402780</title>
<path d="M173.7871,-37.5507C183.4357,-35.0666 194.4229,-32.238 204.9844,-29.5189"/>
<polygon points="206.1107,-32.8432 214.9223,-26.9604 204.3655,-26.0642 206.1107,-32.8432"/>
</g>
<g class="m-node m-flat">
<title>p0x7f2870401eb0</title>
<ellipse cx="39.9767" cy="-18" rx="39.9534" ry="18"/>
<text text-anchor="middle" x="39.9767" y="-13.2">h2d_y</text>
</g>
<g class="m-edge">
<title>p0x7f2870401eb0&#45;&gt;p0x7f2870402bc0</title>
<path d="M74.8986,-26.9906C84.9091,-29.5678 95.8818,-32.3927 106.1075,-35.0253"/>
<polygon points="105.464,-38.4737 116.0208,-37.5775 107.2093,-31.6947 105.464,-38.4737"/>
</g>
</g>
</svg>
</div><aside class="m-note m-info"><h4>Note</h4><p>We encourage users to study and understand the parallel structure of their applications, in order to come up with the best granularity of task decomposition. A refined task graph can have significant performance difference from the raw counterpart.</p></aside></section><section id="C6_OffloadAndUpdateAcudaFlow"><h2><a href="#C6_OffloadAndUpdateAcudaFlow">Offload and Update a cudaFlow</a></h2><p>Many GPU applications require you to launch a cudaFlow mutiple times and update node parameters (e.g., kernel parameters and memory addresses) between iterations. <a href="classtf_1_1cudaFlow.html#a85789ed8a1f47704cf1f1a2b98969444" class="m-doc">tf::<wbr />cudaFlow::<wbr />offload</a> allows you to execute the graph immediately and then update the parameters for the next execution. When you offload a cudaFlow, an executable graph will be created, and you must NOT change the topology but the node parameters between successive executions.</p><pre class="m-code"><span class="mi">1</span><span class="o">:</span> <span class="n">taskflow</span><span class="p">.</span><span class="n">emplace</span><span class="p">([</span><span class="o">&amp;</span><span class="p">]</span> <span class="p">(</span><span class="n">tf</span><span class="o">::</span><span class="n">cudaFlow</span><span class="o">&amp;</span> <span class="n">cf</span><span class="p">)</span> <span class="p">{</span>
<span class="mi">2</span><span class="o">:</span>   <span class="n">tf</span><span class="o">::</span><span class="n">cudaTask</span> <span class="n">task</span> <span class="o">=</span> <span class="n">cf</span><span class="p">.</span><span class="n">kernel</span><span class="p">(</span><span class="n">grid1</span><span class="p">,</span> <span class="n">block1</span><span class="p">,</span> <span class="n">shm1</span><span class="p">,</span> <span class="n">my_kernel</span><span class="p">,</span> <span class="n">args1</span><span class="p">...);</span>
<span class="mi">3</span><span class="o">:</span>   <span class="n">cf</span><span class="p">.</span><span class="n">offload</span><span class="p">();</span>  <span class="c1">// immediately run the cudaFlow once</span>
<span class="mi">4</span><span class="o">:</span>
<span class="mi">5</span><span class="o">:</span>   <span class="n">cf</span><span class="p">.</span><span class="n">update_kernel</span><span class="p">(</span><span class="n">task</span><span class="p">,</span> <span class="n">grid2</span><span class="p">,</span> <span class="n">block2</span><span class="p">,</span> <span class="n">shm2</span><span class="p">,</span> <span class="n">args2</span><span class="p">...);</span>
<span class="mi">6</span><span class="o">:</span>   <span class="n">cf</span><span class="p">.</span><span class="n">offload</span><span class="p">();</span>  <span class="c1">// run the cudaFlow again with the same graph topology</span>
<span class="mi">7</span><span class="o">:</span>                  <span class="c1">// but with different kernel parameters</span>
<span class="mi">8</span><span class="o">:</span> <span class="p">});</span></pre><p>Line 2 creates a kernel task to run <code>my_kernel</code> with the given parameters. Line 3 offloads the cudaFlow and performs an immediate execution; afterwards, we must not modify the graph topology. Line 5 updates the parameters of <code>my_kernel</code> associated with <code>task</code>. Line 6 executes the cudaFlow again with updated kernel parameters. We currently supports the following offload methods:</p><ul><li><a href="classtf_1_1cudaFlow.html#a85789ed8a1f47704cf1f1a2b98969444" class="m-doc">tf::<wbr />cudaFlow::<wbr />offload</a> offloads and runs the cudaFlow once</li><li><a href="classtf_1_1cudaFlow.html#ac2269fd7dc8ca04a294a718204703dad" class="m-doc">tf::<wbr />cudaFlow::<wbr />offload_n</a> offloads and runs the cudaFlow <code>n</code> times</li><li><a href="classtf_1_1cudaFlow.html#a99358da15e3bdfa1faabb3e326130e1f" class="m-doc">tf::<wbr />cudaFlow::<wbr />offload_until</a> offloads and keeps running the cudaFlow until the given predicate returns <code>true</code></li></ul><pre class="m-code"><span class="n">taskflow</span><span class="p">.</span><span class="n">emplace</span><span class="p">(</span><span class="n">tf</span><span class="o">::</span><span class="n">cudaFlow</span><span class="o">&amp;</span> <span class="n">cf</span><span class="p">)</span> <span class="p">{</span>
  <span class="c1">// ... create CUDA tasks</span>
  <span class="n">cf</span><span class="p">.</span><span class="n">offload</span><span class="p">();</span>      <span class="c1">// offload the cudaFlow and run it once</span>
  <span class="n">cf</span><span class="p">.</span><span class="n">offload_n</span><span class="p">(</span><span class="mi">10</span><span class="p">);</span>  <span class="c1">// offload the cudaFlow and run it 10 times</span>
  <span class="n">cf</span><span class="p">.</span><span class="n">offload_until</span><span class="p">([</span><span class="n">repeat</span><span class="o">=</span><span class="mi">5</span><span class="p">]</span> <span class="p">()</span> <span class="k">mutable</span> <span class="p">{</span> <span class="k">return</span> <span class="n">repeat</span><span class="o">--</span> <span class="o">==</span> <span class="mi">0</span><span class="p">;</span> <span class="p">})</span>  <span class="c1">// 5 times</span>
<span class="p">};</span></pre><p>After you offload a cudaFlow (possibly multiple times), it is considered executed, and the executor will not run an offloaded cudaFlow after the cudaFlow task callable. On the other hand, if a cudaFlow is not offloaded, the executor runs it once. For example, the following two versions represent the same execution logic.</p><pre class="m-code"><span class="c1">// version 1: explicitly offload a cudaFlow</span>
<span class="n">taskflow</span><span class="p">.</span><span class="n">emplace</span><span class="p">(</span><span class="n">tf</span><span class="o">::</span><span class="n">cudaFlow</span><span class="o">&amp;</span> <span class="n">cf</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">cf</span><span class="p">.</span><span class="n">kernel</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">block</span><span class="p">,</span> <span class="n">shm</span><span class="p">,</span> <span class="n">my_kernel</span><span class="p">,</span> <span class="n">my_kernel_args</span><span class="p">).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;my_kernel&quot;</span><span class="p">);</span>
  <span class="n">cf</span><span class="p">.</span><span class="n">offload</span><span class="p">();</span>
<span class="p">};</span>

<span class="c1">// version 2 (same as version 1): executor offloads the cudaFlow</span>
<span class="n">taskflow</span><span class="p">.</span><span class="n">emplace</span><span class="p">(</span><span class="n">tf</span><span class="o">::</span><span class="n">cudaFlow</span><span class="o">&amp;</span> <span class="n">cf</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">cf</span><span class="p">.</span><span class="n">kernel</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">block</span><span class="p">,</span> <span class="n">shm</span><span class="p">,</span> <span class="n">my_kernel</span><span class="p">,</span> <span class="n">my_kernel_args</span><span class="p">).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;my_kernel&quot;</span><span class="p">);</span>
<span class="p">};</span></pre><p>We currently support the following methods to update task parameters from an offloaded cudaFlow:</p><ul><li><a href="classtf_1_1cudaFlow.html#abab3a11129e6286c1de3deecedae8090" class="m-doc">tf::<wbr />cudaFlow::<wbr />update_kernel</a> updates the parameters of a kernel task</li><li><a href="classtf_1_1cudaFlow.html#a7972c77ba5f533b69e4b1dc55e87374d" class="m-doc">tf::<wbr />cudaFlow::<wbr />update_copy</a> updates the parameters of a memcpy task to form a copy task</li><li><a href="classtf_1_1cudaFlow.html#af5f4cd1fc858a7725bbf57db629bdc34" class="m-doc">tf::<wbr />cudaFlow::<wbr />update_memcpy</a> updates the parameters of a memcpy task</li><li><a href="classtf_1_1cudaFlow.html#a603072d44265de60647a7bcc5aaebace" class="m-doc">tf::<wbr />cudaFlow::<wbr />update_memset</a> updates the parameters of a memset task</li><li><a href="classtf_1_1cudaFlow.html#a4a319c3e47fc538f6c31a7317c6a17e0" class="m-doc">tf::<wbr />cudaFlow::<wbr />update_fill</a> updates the parameters of a memset task to form a fill task</li><li><a href="classtf_1_1cudaFlow.html#a62a042795e4a089ab633d809af6108a6" class="m-doc">tf::<wbr />cudaFlow::<wbr />update_zero</a> updates the parameters of a memset task to form a zero task</li></ul><p>Please visit the reference page of <a href="classtf_1_1cudaFlow.html" class="m-doc">tf::<wbr />cudaFlow</a> for more details.</p><aside class="m-note m-warning"><h4>Attention</h4><p>There are quite a few limitations on update methods:</p><ul><li>kernel task<ul><li>The kernel function is not allowed to change</li></ul></li><li>memset and memcpy tasks:<ul><li>The CUDA device(s) to which the operand(s) was allocated/mapped cannot change</li><li>The source/destination memory must be allocated from the same contexts as the original source/destination memory.</li></ul></li></ul></aside></section><section id="C6_UsecudaFlowInAStandaloneEnvironment"><h2><a href="#C6_UsecudaFlowInAStandaloneEnvironment">Use cudaFlow in a Standalone Environment</a></h2><p>You can use <a href="classtf_1_1cudaFlow.html" class="m-doc">tf::<wbr />cudaFlow</a> in a standalone environment without going through <a href="classtf_1_1Taskflow.html" class="m-doc">tf::<wbr />Taskflow</a> and offloads it to GPU from the caller thread. All the features we have discussed so far are applicable for the standalone use.</p><pre class="m-code"><span class="n">tf</span><span class="o">::</span><span class="n">cudaFlow</span> <span class="n">cf</span><span class="p">;</span>  <span class="c1">// create a standalone cudaFlow</span>

<span class="n">tf</span><span class="o">::</span><span class="n">cudaTask</span> <span class="n">h2d_x</span> <span class="o">=</span> <span class="n">cf</span><span class="p">.</span><span class="n">copy</span><span class="p">(</span><span class="n">dx</span><span class="p">,</span> <span class="n">hx</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span> <span class="n">N</span><span class="p">).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;h2d_x&quot;</span><span class="p">);</span>
<span class="n">tf</span><span class="o">::</span><span class="n">cudaTask</span> <span class="n">h2d_y</span> <span class="o">=</span> <span class="n">cf</span><span class="p">.</span><span class="n">copy</span><span class="p">(</span><span class="n">dy</span><span class="p">,</span> <span class="n">hy</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span> <span class="n">N</span><span class="p">).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;h2d_y&quot;</span><span class="p">);</span>
<span class="n">tf</span><span class="o">::</span><span class="n">cudaTask</span> <span class="n">d2h_x</span> <span class="o">=</span> <span class="n">cf</span><span class="p">.</span><span class="n">copy</span><span class="p">(</span><span class="n">hx</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span> <span class="n">dx</span><span class="p">,</span> <span class="n">N</span><span class="p">).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;d2h_x&quot;</span><span class="p">);</span>
<span class="n">tf</span><span class="o">::</span><span class="n">cudaTask</span> <span class="n">d2h_y</span> <span class="o">=</span> <span class="n">cf</span><span class="p">.</span><span class="n">copy</span><span class="p">(</span><span class="n">hy</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span> <span class="n">dy</span><span class="p">,</span> <span class="n">N</span><span class="p">).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;d2h_y&quot;</span><span class="p">);</span>
<span class="n">tf</span><span class="o">::</span><span class="n">cudaTask</span> <span class="n">saxpy</span> <span class="o">=</span> <span class="n">cf</span><span class="p">.</span><span class="n">kernel</span><span class="p">((</span><span class="n">N</span><span class="o">+</span><span class="mi">255</span><span class="p">)</span><span class="o">/</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">saxpy</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="mf">2.0f</span><span class="p">,</span> <span class="n">dx</span><span class="p">,</span> <span class="n">dy</span><span class="p">)</span>
                       <span class="p">.</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;saxpy&quot;</span><span class="p">);</span>

<span class="n">saxpy</span><span class="p">.</span><span class="n">succeed</span><span class="p">(</span><span class="n">h2d_x</span><span class="p">,</span> <span class="n">h2d_y</span><span class="p">)</span>   <span class="c1">// kernel runs after  host-to-device copy</span>
     <span class="p">.</span><span class="n">precede</span><span class="p">(</span><span class="n">d2h_x</span><span class="p">,</span> <span class="n">d2h_y</span><span class="p">);</span>  <span class="c1">// kernel runs before device-to-host copy</span>

<span class="n">cf</span><span class="p">.</span><span class="n">offload</span><span class="p">();</span>  <span class="c1">// offload and run the standalone cudaFlow once</span></pre><aside class="m-note m-warning"><h4>Attention</h4><p>When using cudaFlow in a standalone environment, it is your choice and responsibility to decide its GPU context and ensure that GPU memory operations are correctly performed.</p></aside></section>
      </div>
    </div>
  </div>
</article></main>
<div class="m-doc-search" id="search">
  <a href="#!" onclick="return hideSearch()"></a>
  <div class="m-container">
    <div class="m-row">
      <div class="m-col-m-8 m-push-m-2">
        <div class="m-doc-search-header m-text m-small">
          <div><span class="m-label m-default">Tab</span> / <span class="m-label m-default">T</span> to search, <span class="m-label m-default">Esc</span> to close</div>
          <div id="search-symbolcount">&hellip;</div>
        </div>
        <div class="m-doc-search-content">
          <form>
            <input type="search" name="q" id="search-input" placeholder="Loading &hellip;" disabled="disabled" autofocus="autofocus" autocomplete="off" spellcheck="false" />
          </form>
          <noscript class="m-text m-danger m-text-center">Unlike everything else in the docs, the search functionality <em>requires</em> JavaScript.</noscript>
          <div id="search-help" class="m-text m-dim m-text-center">
            <p class="m-noindent">Search for symbols, directories, files, pages or
            modules. You can omit any prefix from the symbol or file path; adding a
            <code>:</code> or <code>/</code> suffix lists all members of given symbol or
            directory.</p>
            <p class="m-noindent">Use <span class="m-label m-dim">&darr;</span>
            / <span class="m-label m-dim">&uarr;</span> to navigate through the list,
            <span class="m-label m-dim">Enter</span> to go.
            <span class="m-label m-dim">Tab</span> autocompletes common prefix, you can
            copy a link to the result using <span class="m-label m-dim">⌘</span>
            <span class="m-label m-dim">L</span> while <span class="m-label m-dim">⌘</span>
            <span class="m-label m-dim">M</span> produces a Markdown link.</p>
          </div>
          <div id="search-notfound" class="m-text m-warning m-text-center">Sorry, nothing was found.</div>
          <ul id="search-results"></ul>
        </div>
      </div>
    </div>
  </div>
</div>
<script src="search-v1.js"></script>
<script src="searchdata-v1.js" async="async"></script>
<footer><nav>
  <div class="m-container">
    <div class="m-row">
      <div class="m-col-l-10 m-push-l-1">
        <p>Taskflow handbook is part of the <a href="https://taskflow.github.io">Taskflow project</a>, copyright © <a href="https://tsung-wei-huang.github.io/">Dr. Tsung-Wei Huang</a>, 2018&ndash;2020.<br />Generated by <a href="https://doxygen.org/">Doxygen</a> 1.8.14 and <a href="https://mcss.mosra.cz/">m.css</a>.</p>
      </div>
    </div>
  </div>
</nav></footer>
</body>
</html>
