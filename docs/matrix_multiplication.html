<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Learning from Examples &raquo; Matrix Multiplication | Taskflow QuickStart</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,400i,600,600i%7CSource+Code+Pro:400,400i,600" />
  <link rel="stylesheet" href="m-dark+documentation.compiled.css" />
  <link rel="icon" href="favicon.ico" type="image/x-icon" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="theme-color" content="#22272e" />
</head>
<body>
<header><nav id="navigation">
  <div class="m-container">
    <div class="m-row">
      <span id="m-navbar-brand" class="m-col-t-8 m-col-m-none m-left-m">
        <a href="https://taskflow.github.io"><img src="taskflow_logo.png" alt="" />Taskflow</a> <span class="m-breadcrumb">|</span> <a href="index.html" class="m-thin">QuickStart</a>
      </span>
      <div class="m-col-t-4 m-hide-m m-text-right m-nopadr">
        <a href="#search" class="m-doc-search-icon" title="Search" onclick="return showSearch()"><svg style="height: 0.9rem;" viewBox="0 0 16 16">
          <path id="m-doc-search-icon-path" d="m6 0c-3.31 0-6 2.69-6 6 0 3.31 2.69 6 6 6 1.49 0 2.85-0.541 3.89-1.44-0.0164 0.338 0.147 0.759 0.5 1.15l3.22 3.79c0.552 0.614 1.45 0.665 2 0.115 0.55-0.55 0.499-1.45-0.115-2l-3.79-3.22c-0.392-0.353-0.812-0.515-1.15-0.5 0.895-1.05 1.44-2.41 1.44-3.89 0-3.31-2.69-6-6-6zm0 1.56a4.44 4.44 0 0 1 4.44 4.44 4.44 4.44 0 0 1-4.44 4.44 4.44 4.44 0 0 1-4.44-4.44 4.44 4.44 0 0 1 4.44-4.44z"/>
        </svg></a>
        <a id="m-navbar-show" href="#navigation" title="Show navigation"></a>
        <a id="m-navbar-hide" href="#" title="Hide navigation"></a>
      </div>
      <div id="m-navbar-collapse" class="m-col-t-12 m-show-m m-col-m-none m-right-m">
        <div class="m-row">
          <ol class="m-col-t-6 m-col-m-none">
            <li><a href="pages.html">Handbook</a></li>
            <li><a href="namespaces.html">Namespaces</a></li>
          </ol>
          <ol class="m-col-t-6 m-col-m-none" start="3">
            <li><a href="annotated.html">Classes</a></li>
            <li><a href="files.html">Files</a></li>
            <li class="m-show-m"><a href="#search" class="m-doc-search-icon" title="Search" onclick="return showSearch()"><svg style="height: 0.9rem;" viewBox="0 0 16 16">
              <use href="#m-doc-search-icon-path" />
            </svg></a></li>
          </ol>
        </div>
      </div>
    </div>
  </div>
</nav></header>
<main><article>
  <div class="m-container m-container-inflatable">
    <div class="m-row">
      <div class="m-col-l-10 m-push-l-1">
        <h1>
          <span class="m-breadcrumb"><a href="Examples.html">Learning from Examples</a> &raquo;</span>
          Matrix Multiplication
        </h1>
        <div class="m-block m-default">
          <h3>Contents</h3>
          <ul>
            <li><a href="#MatrixMultiplicationProblem">Problem Formulation</a></li>
            <li><a href="#MatrixMultiplicationParallelPattern">Parallel Patterns</a></li>
            <li><a href="#GPUAcceleratedMatrixMultiplication">GPU-based Acceleration</a></li>
            <li><a href="#MatrixMultiplicationBenchmarking">Benchmarking</a></li>
          </ul>
        </div>
<p>We study the classic problem, <em>2D matrix multiplication</em>. We will start with a short introduction about the problem and then discuss how to solve it using CPU and GPU parallel computing.</p><section id="MatrixMultiplicationProblem"><h2><a href="#MatrixMultiplicationProblem">Problem Formulation</a></h2><p>We are multiplying two matrices, A (MxK) and B (KxN). The numbers of columns of A must match the number of rows of B. The output matrix C has the shape of (MxN) where M is the rows of A and N the columns of B. The following example multiplies a 3x3 matrix with a 3x2 matrix to derive a 3x2 matrix.</p><img class="m-image" src="matrix_multiplication_1.png" alt="Image" style="width: 50%;" /><p>As a general view, for each element of C we iterate a complete row of A and a complete column of B, multiplying each element and summing them.</p><img class="m-image" src="matrix_multiplication_2.png" alt="Image" style="width: 50%;" /><p>We can implement matrix multiplication using three nested loops.</p><pre class="m-code"><span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">m</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">m</span><span class="o">&lt;</span><span class="n">M</span><span class="p">;</span> <span class="n">m</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">n</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">n</span><span class="o">&lt;</span><span class="n">N</span><span class="p">;</span> <span class="n">n</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">C</span><span class="p">[</span><span class="n">m</span><span class="p">][</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">k</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">k</span><span class="o">&lt;</span><span class="n">K</span><span class="p">;</span> <span class="n">k</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">C</span><span class="p">[</span><span class="n">m</span><span class="p">][</span><span class="n">n</span><span class="p">]</span> <span class="o">+=</span> <span class="n">A</span><span class="p">[</span><span class="n">m</span><span class="p">][</span><span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">B</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="n">n</span><span class="p">];</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span></pre></section><section id="MatrixMultiplicationParallelPattern"><h2><a href="#MatrixMultiplicationParallelPattern">Parallel Patterns</a></h2><p>At a fine-grained level, computing each element of C is independent of each other. Similarly, computing each row of C or each column of C is also independent of one another. With task parallelism, we prefer <em>coarse-grained</em> model to have each task perform rather large computation to amortize the overhead of creating and scheduling tasks. In this case, we avoid intensive tasks each working on only a single element. by creating a task per row of C to multiply a row of A by every column of B.</p><pre class="m-code"><span class="c1">// C = A * B</span>
<span class="c1">// A is a MxK matrix, B is a KxN matrix, and C is a MxN matrix</span>
<span class="kt">void</span> <span class="nf">matrix_multiplication</span><span class="p">(</span><span class="kt">int</span><span class="o">**</span> <span class="n">A</span><span class="p">,</span> <span class="kt">int</span><span class="o">**</span> <span class="n">B</span><span class="p">,</span> <span class="kt">int</span><span class="o">**</span> <span class="n">C</span><span class="p">,</span> <span class="kt">int</span> <span class="n">M</span><span class="p">,</span> <span class="kt">int</span> <span class="n">K</span><span class="p">,</span> <span class="kt">int</span> <span class="n">N</span><span class="p">)</span> <span class="p">{</span>

  <span class="n">tf</span><span class="o">::</span><span class="n">Taskflow</span> <span class="n">taskflow</span><span class="p">;</span>
  <span class="n">tf</span><span class="o">::</span><span class="n">Executor</span> <span class="n">executor</span><span class="p">;</span>
  
  <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">m</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">m</span><span class="o">&lt;</span><span class="n">M</span><span class="p">;</span> <span class="o">++</span><span class="n">m</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">taskflow</span><span class="p">.</span><span class="n">emplace</span><span class="p">([</span><span class="n">m</span><span class="p">,</span> <span class="o">&amp;</span><span class="p">]</span> <span class="p">()</span> <span class="p">{</span>
      <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">n</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">n</span><span class="o">&lt;</span><span class="n">N</span><span class="p">;</span> <span class="n">n</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
        <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">k</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">k</span><span class="o">&lt;</span><span class="n">K</span><span class="p">;</span> <span class="n">k</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
          <span class="n">C</span><span class="p">[</span><span class="n">m</span><span class="p">][</span><span class="n">n</span><span class="p">]</span> <span class="o">+=</span> <span class="n">A</span><span class="p">[</span><span class="n">m</span><span class="p">][</span><span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">B</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="n">n</span><span class="p">];</span>
        <span class="p">}</span>
      <span class="p">}</span>
    <span class="p">});</span>
  <span class="p">}</span>

  <span class="n">executor</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">taskflow</span><span class="p">).</span><span class="n">wait</span><span class="p">();</span>
<span class="p">}</span></pre><p>Instead of creating tasks one-by-one over a loop, you can leverage <a href="classtf_1_1FlowBuilder.html#ab8417b211b18bb1e0f45a049331f084d" class="m-doc">Taskflow::<wbr />for_each_index</a> to create a <em>parallel-for</em> task. A parallel-for task spawns a subflow to perform parallel iterations over the given range.</p><pre class="m-code"><span class="c1">// perform parallel iterations on the range [0, M) with the step size of 1</span>
<span class="n">tf</span><span class="o">::</span><span class="n">Task</span> <span class="n">task</span> <span class="o">=</span> <span class="n">taskflow</span><span class="p">.</span><span class="n">for_each_index</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="o">&amp;</span><span class="p">]</span> <span class="p">(</span><span class="kt">int</span> <span class="n">m</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">n</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">n</span><span class="o">&lt;</span><span class="n">N</span><span class="p">;</span> <span class="n">n</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">k</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">k</span><span class="o">&lt;</span><span class="n">K</span><span class="p">;</span> <span class="n">k</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">C</span><span class="p">[</span><span class="n">m</span><span class="p">][</span><span class="n">n</span><span class="p">]</span> <span class="o">+=</span> <span class="n">A</span><span class="p">[</span><span class="n">m</span><span class="p">][</span><span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">B</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="n">n</span><span class="p">];</span>
    <span class="p">}</span>   
  <span class="p">}</span>   
<span class="p">});</span></pre><p>Please visit <a href="A1ForEach.html" class="m-doc">Parallel Iterations</a> for more details.</p></section><section id="GPUAcceleratedMatrixMultiplication"><h2><a href="#GPUAcceleratedMatrixMultiplication">GPU-based Acceleration</a></h2><p>GPU is able to do a lot of parallel computations more than CPUs. It is especially useful for data-intensive computing such as matrix multiplication. With GPU, we express the parallel patterns at a fine-grained level. The kernel, written in CUDA, is described as follows:</p><pre class="m-code"><span class="c1">// CUDA kernel to perform matrix multiplication</span>
<span class="n">__global__</span> <span class="kt">void</span> <span class="n">matmul</span><span class="p">(</span><span class="kt">int</span> <span class="o">*</span><span class="n">A</span><span class="p">,</span> <span class="kt">int</span> <span class="o">*</span><span class="n">B</span><span class="p">,</span> <span class="kt">int</span> <span class="o">*</span><span class="n">C</span><span class="p">,</span> <span class="kt">int</span> <span class="n">M</span><span class="p">,</span> <span class="kt">int</span> <span class="n">K</span><span class="p">,</span> <span class="kt">int</span> <span class="n">N</span><span class="p">)</span> <span class="p">{</span>
  <span class="kt">int</span> <span class="n">row</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">y</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
  <span class="kt">int</span> <span class="n">col</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
  <span class="kt">int</span> <span class="n">sum</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
  <span class="k">if</span><span class="p">(</span><span class="n">col</span> <span class="o">&lt;</span> <span class="n">N</span> <span class="o">&amp;&amp;</span> <span class="n">row</span> <span class="o">&lt;</span> <span class="n">M</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">K</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">sum</span> <span class="o">+=</span> <span class="n">a</span><span class="p">[</span><span class="n">row</span> <span class="o">*</span> <span class="n">K</span> <span class="o">+</span> <span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">b</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">N</span> <span class="o">+</span> <span class="n">col</span><span class="p">];</span>
    <span class="p">}</span>
    <span class="n">c</span><span class="p">[</span><span class="n">row</span> <span class="o">*</span> <span class="n">N</span> <span class="o">+</span> <span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">sum</span><span class="p">;</span>
  <span class="p">}</span>
<span class="p">}</span></pre><p>Each CUDA thread corresponds to an element of C and compute its result. Instead of storing each matrix in a 2D array, we use 1D layout to ease the data transfer between CPU and GPU. In a row-major layout, an element <code>(x, y)</code> in the 2D matrix can be addressed at <code>x * width + y</code> in the transformed 1D layout.</p><img class="m-image" src="matrix_multiplication_4.png" alt="Image" style="width: 70%;" /><p>The next step is to allocate memory for A, B, and C at a GPU. We create three tasks each calling <code>cudaMalloc</code> to allocate space for one matrix. Then, we create a cudaFlow to offload matrix multiplication to a GPU. The entire code is described as follows:</p><pre class="m-code"><span class="kt">void</span> <span class="nf">matrix_multiplication</span><span class="p">(</span><span class="kt">int</span><span class="o">*</span> <span class="n">A</span><span class="p">,</span> <span class="kt">int</span><span class="o">*</span> <span class="n">B</span><span class="p">,</span> <span class="kt">int</span><span class="o">*</span> <span class="n">C</span><span class="p">,</span> <span class="kt">int</span> <span class="n">M</span><span class="p">,</span> <span class="kt">int</span> <span class="n">K</span><span class="p">,</span> <span class="kt">int</span> <span class="n">N</span><span class="p">)</span> <span class="p">{</span>
  
  <span class="n">tf</span><span class="o">::</span><span class="n">Taskflow</span> <span class="n">taskflow</span><span class="p">;</span>
  <span class="n">tf</span><span class="o">::</span><span class="n">Executor</span> <span class="n">executor</span><span class="p">;</span>

  <span class="c1">// allocate the host and gpu storage for A</span>
  <span class="n">tf</span><span class="o">::</span><span class="n">Task</span> <span class="n">allocate_a</span> <span class="o">=</span> <span class="n">taskflow</span><span class="p">.</span><span class="n">emplace</span><span class="p">([</span><span class="o">&amp;</span><span class="p">](){</span>
    <span class="n">cudaMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">da</span><span class="p">,</span> <span class="n">M</span><span class="o">*</span><span class="n">K</span><span class="o">*</span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">));</span>
  <span class="p">}).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;allocate_a&quot;</span><span class="p">);</span>
  
  <span class="c1">// allocate the host and gpu storage for B</span>
  <span class="n">tf</span><span class="o">::</span><span class="n">Task</span> <span class="n">allocate_b</span> <span class="o">=</span> <span class="n">taskflow</span><span class="p">.</span><span class="n">emplace</span><span class="p">([</span><span class="o">&amp;</span><span class="p">](){</span>
    <span class="n">cudaMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">db</span><span class="p">,</span> <span class="n">K</span><span class="o">*</span><span class="n">N</span><span class="o">*</span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">));</span>
  <span class="p">}).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;allocate_b&quot;</span><span class="p">);</span>
  
  <span class="c1">// allocate the host and gpu storage for C</span>
  <span class="n">tf</span><span class="o">::</span><span class="n">Task</span> <span class="n">allocate_c</span> <span class="o">=</span> <span class="n">taskflow</span><span class="p">.</span><span class="n">emplace</span><span class="p">([</span><span class="o">&amp;</span><span class="p">](){</span>
    <span class="n">cudaMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">dc</span><span class="p">,</span> <span class="n">M</span><span class="o">*</span><span class="n">N</span><span class="o">*</span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">));</span>
  <span class="p">}).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;allocate_c&quot;</span><span class="p">);</span>
  
  <span class="c1">// create a cudaFlow to run the matrix multiplication</span>
  <span class="n">tf</span><span class="o">::</span><span class="n">Task</span> <span class="n">cudaFlow</span> <span class="o">=</span> <span class="n">taskflow</span><span class="p">.</span><span class="n">emplace</span><span class="p">([</span><span class="o">&amp;</span><span class="p">](</span><span class="n">tf</span><span class="o">::</span><span class="n">cudaFlow</span><span class="o">&amp;</span> <span class="n">cf</span><span class="p">){</span>
  
    <span class="c1">// copy data to da, db, and dc</span>
    <span class="n">tf</span><span class="o">::</span><span class="n">cudaTask</span> <span class="n">copy_da</span> <span class="o">=</span> <span class="n">cf</span><span class="p">.</span><span class="n">copy</span><span class="p">(</span><span class="n">da</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">M</span><span class="o">*</span><span class="n">K</span><span class="p">).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;H2D_A&quot;</span><span class="p">);</span>
    <span class="n">tf</span><span class="o">::</span><span class="n">cudaTask</span> <span class="n">copy_db</span> <span class="o">=</span> <span class="n">cf</span><span class="p">.</span><span class="n">copy</span><span class="p">(</span><span class="n">db</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">K</span><span class="o">*</span><span class="n">N</span><span class="p">).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;H2D_B&quot;</span><span class="p">);</span>
    <span class="n">tf</span><span class="o">::</span><span class="n">cudaTask</span> <span class="n">copy_hc</span> <span class="o">=</span> <span class="n">cf</span><span class="p">.</span><span class="n">copy</span><span class="p">(</span><span class="n">C</span><span class="p">,</span> <span class="n">dc</span><span class="p">,</span> <span class="n">M</span><span class="o">*</span><span class="n">N</span><span class="p">).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;D2H_C&quot;</span><span class="p">);</span>
  
    <span class="n">dim3</span> <span class="n">grid</span>  <span class="p">((</span><span class="n">K</span><span class="o">+</span><span class="mi">16-1</span><span class="p">)</span><span class="o">/</span><span class="mi">16</span><span class="p">,</span> <span class="p">(</span><span class="n">M</span><span class="o">+</span><span class="mi">16-1</span><span class="p">)</span><span class="o">/</span><span class="mi">16</span><span class="p">);</span>
    <span class="n">dim3</span> <span class="n">block</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">);</span>
  
    <span class="n">tf</span><span class="o">::</span><span class="n">cudaTask</span> <span class="n">kmatmul</span> <span class="o">=</span> <span class="n">cf</span><span class="p">.</span><span class="n">kernel</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">block</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">matmul</span><span class="p">,</span> <span class="n">da</span><span class="p">,</span> <span class="n">db</span><span class="p">,</span> <span class="n">dc</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
                             <span class="p">.</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;matmul&quot;</span><span class="p">);</span>
  
    <span class="n">kmatmul</span><span class="p">.</span><span class="n">succeed</span><span class="p">(</span><span class="n">copy_da</span><span class="p">,</span> <span class="n">copy_db</span><span class="p">)</span>
           <span class="p">.</span><span class="n">precede</span><span class="p">(</span><span class="n">copy_hc</span><span class="p">);</span>
  
  <span class="p">}).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;cudaFlow&quot;</span><span class="p">);</span>
  
  <span class="c1">// free the gpu storage</span>
  <span class="k">auto</span> <span class="n">free</span> <span class="o">=</span> <span class="n">taskflow</span><span class="p">.</span><span class="n">emplace</span><span class="p">([</span><span class="o">&amp;</span><span class="p">](){</span>
    <span class="n">cudaFree</span><span class="p">(</span><span class="n">da</span><span class="p">);</span>
    <span class="n">cudaFree</span><span class="p">(</span><span class="n">db</span><span class="p">);</span>
    <span class="n">cudaFree</span><span class="p">(</span><span class="n">dc</span><span class="p">);</span>
  <span class="p">}).</span><span class="n">name</span><span class="p">(</span><span class="s">&quot;free&quot;</span><span class="p">);</span>
  
  <span class="c1">// create dependency</span>
  <span class="n">cudaFlow</span><span class="p">.</span><span class="n">succeed</span><span class="p">(</span><span class="n">allocate_a</span><span class="p">,</span> <span class="n">allocate_b</span><span class="p">,</span> <span class="n">allocate_c</span><span class="p">)</span>
          <span class="p">.</span><span class="n">precede</span><span class="p">(</span><span class="n">free</span><span class="p">);</span>
  
  <span class="c1">// dump the graph without unfolding the cudaFlow</span>
  <span class="n">taskflow</span><span class="p">.</span><span class="n">dump</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="p">);</span>

  <span class="c1">// run the taskflow</span>
  <span class="n">executor</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">taskflow</span><span class="p">).</span><span class="n">wait</span><span class="p">();</span>

  <span class="c1">// dump the entire execution graph including unfolded cudaFlow</span>
  <span class="n">taskflow</span><span class="p">.</span><span class="n">dump</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="p">);</span>
<span class="p">}</span></pre><p>Within the cudaFlow, we create two host-to-device (H2D) tasks that copy data from <code>A</code> and <code>B</code> to <code>da</code> and <code>db</code>, one device-to-host (D2H) task that copies the result from <code>dc</code> to <code>C</code>, and one kernel task that launches <code>matmul</code> on the GPU (by default, GPU 0). H2D tasks precede the kernel and the kernel precedes the D2H task. These GPU operations form a GPU task graph managed by a cudaFlow. The first dump of the taskflow gives the following graph:</p><div class="m-graph"><svg style="width: 25.062rem; height: 11.750rem;" viewBox="0.00 0.00 400.73 188.00">
<g transform="scale(1 1) rotate(0) translate(4 184)">
<title>Taskflow</title>
<g class="m-node m-flat">
<title>p0x55d923794f10</title>
<ellipse cx="59.6663" cy="-162" rx="59.8331" ry="18"/>
<text text-anchor="middle" x="59.6663" y="-157.2">allocate_a</text>
</g>
<g class="m-node">
<title>p0x55d923795240</title>
<polygon points="239.1442,-108 236.1442,-112 215.1442,-112 212.1442,-108 154.1884,-108 154.1884,-72 239.1442,-72 239.1442,-108"/>
<text text-anchor="middle" x="196.6663" y="-85.2">cudaFlow</text>
</g>
<g class="m-edge">
<title>p0x55d923794f10&#45;&gt;p0x55d923795240</title>
<path d="M89.3933,-146.3771C108.0395,-136.5776 132.401,-123.7745 153.1949,-112.8463"/>
<polygon points="154.9381,-115.8842 162.1618,-108.1338 151.6815,-109.6878 154.9381,-115.8842"/>
</g>
<g class="m-node m-flat">
<title>p0x55d923795350</title>
<ellipse cx="196.6663" cy="-18" rx="29.4575" ry="18"/>
<text text-anchor="middle" x="196.6663" y="-13.2">free</text>
</g>
<g class="m-edge">
<title>p0x55d923795240&#45;&gt;p0x55d923795350</title>
<path d="M196.6663,-71.8314C196.6663,-64.131 196.6663,-54.9743 196.6663,-46.4166"/>
<polygon points="200.1664,-46.4132 196.6663,-36.4133 193.1664,-46.4133 200.1664,-46.4132"/>
</g>
<g class="m-node m-flat">
<title>p0x55d923795020</title>
<ellipse cx="196.6663" cy="-162" rx="59.8331" ry="18"/>
<text text-anchor="middle" x="196.6663" y="-157.2">allocate_b</text>
</g>
<g class="m-edge">
<title>p0x55d923795020&#45;&gt;p0x55d923795240</title>
<path d="M196.6663,-143.8314C196.6663,-136.131 196.6663,-126.9743 196.6663,-118.4166"/>
<polygon points="200.1664,-118.4132 196.6663,-108.4133 193.1664,-118.4133 200.1664,-118.4132"/>
</g>
<g class="m-node m-flat">
<title>p0x55d923795130</title>
<ellipse cx="333.6663" cy="-162" rx="59.1273" ry="18"/>
<text text-anchor="middle" x="333.6663" y="-157.2">allocate_c</text>
</g>
<g class="m-edge">
<title>p0x55d923795130&#45;&gt;p0x55d923795240</title>
<path d="M303.9394,-146.3771C285.2931,-136.5776 260.9316,-123.7745 240.1378,-112.8463"/>
<polygon points="241.6511,-109.6878 231.1709,-108.1338 238.3946,-115.8842 241.6511,-109.6878"/>
</g>
</g>
</svg>
</div><p>A cudaFlow encapsulates a GPU task dependency graph similar to a subflow (see <a href="chapter3.html" class="m-doc">Dynamic Tasking</a>). In order to visualize it, we need to execute the graph first and then dump the taskflow.</p><div class="m-graph"><svg style="width: 38.125rem; height: 23.250rem;" viewBox="0.00 0.00 609.73 372.00">
<g transform="scale(1 1) rotate(0) translate(4 368)">
<title>Taskflow</title>
<g class="m-cluster">
<title>cluster_p0x5558af971240</title>
<polygon points="127.6663,-64 127.6663,-356 337.6663,-356 337.6663,-64 127.6663,-64"/>
<text text-anchor="middle" x="232.6663" y="-339.2">cudaFlow: cudaFlow</text>
</g>
<g class="m-node m-flat">
<title>p0x5558af970f10</title>
<ellipse cx="59.6663" cy="-162" rx="59.8331" ry="18"/>
<text text-anchor="middle" x="59.6663" y="-157.2">allocate_a</text>
</g>
<g class="m-node">
<title>p0x5558af971240</title>
<polygon points="328.1442,-108 325.1442,-112 304.1442,-112 301.1442,-108 243.1884,-108 243.1884,-72 328.1442,-72 328.1442,-108"/>
<text text-anchor="middle" x="285.6663" y="-85.2">cudaFlow</text>
</g>
<g class="m-edge">
<title>p0x5558af970f10&#45;&gt;p0x5558af971240</title>
<path d="M100.8554,-148.8778C138.1406,-136.9994 193.2359,-119.4469 233.569,-106.5974"/>
<polygon points="234.7607,-109.8911 243.2264,-103.5207 232.6358,-103.2214 234.7607,-109.8911"/>
</g>
<g class="m-node m-flat">
<title>p0x5558af971350</title>
<ellipse cx="285.6663" cy="-18" rx="29.4575" ry="18"/>
<text text-anchor="middle" x="285.6663" y="-13.2">free</text>
</g>
<g class="m-edge">
<title>p0x5558af971240&#45;&gt;p0x5558af971350</title>
<path d="M285.6663,-71.8314C285.6663,-64.131 285.6663,-54.9743 285.6663,-46.4166"/>
<polygon points="289.1664,-46.4132 285.6663,-36.4133 282.1664,-46.4133 289.1664,-46.4132"/>
</g>
<g class="m-node m-flat">
<title>p0x5558af971020</title>
<ellipse cx="405.6663" cy="-162" rx="59.8331" ry="18"/>
<text text-anchor="middle" x="405.6663" y="-157.2">allocate_b</text>
</g>
<g class="m-edge">
<title>p0x5558af971020&#45;&gt;p0x5558af971240</title>
<path d="M378.736,-145.8418C362.848,-136.309 342.4611,-124.0769 324.8198,-113.4921"/>
<polygon points="326.2589,-110.2739 315.8832,-108.1301 322.6574,-116.2764 326.2589,-110.2739"/>
</g>
<g class="m-node m-flat">
<title>p0x5558af971130</title>
<ellipse cx="542.6663" cy="-162" rx="59.1273" ry="18"/>
<text text-anchor="middle" x="542.6663" y="-157.2">allocate_c</text>
</g>
<g class="m-edge">
<title>p0x5558af971130&#45;&gt;p0x5558af971240</title>
<path d="M499.0698,-149.7862C454.5479,-137.3131 385.4131,-117.9446 337.9703,-104.6533"/>
<polygon points="338.7659,-101.2415 328.1925,-101.9139 336.8775,-107.9819 338.7659,-101.2415"/>
</g>
<g class="m-node m-flat">
<title>p0x7f6fd8000b20</title>
<ellipse cx="285.6663" cy="-306" rx="44.2867" ry="18"/>
<text text-anchor="middle" x="285.6663" y="-301.2">H2D_a</text>
</g>
<g class="m-node">
<title>p0x7f6fd8000db0</title>
<polygon points="319.121,-252 254.2117,-252 250.2117,-248 250.2117,-216 315.121,-216 319.121,-220 319.121,-252"/>
<polyline points="315.121,-248 250.2117,-248 "/>
<polyline points="315.121,-248 315.121,-216 "/>
<polyline points="315.121,-248 319.121,-252 "/>
<text text-anchor="middle" x="284.6663" y="-229.2">matmul</text>
</g>
<g class="m-edge">
<title>p0x7f6fd8000b20&#45;&gt;p0x7f6fd8000db0</title>
<path d="M285.414,-287.8314C285.307,-280.131 285.1799,-270.9743 285.061,-262.4166"/>
<polygon points="288.5607,-262.3637 284.9221,-252.4133 281.5614,-262.4609 288.5607,-262.3637"/>
</g>
<g class="m-node m-flat">
<title>p0x7f6fd8000ce0</title>
<ellipse cx="284.6663" cy="-162" rx="43.5809" ry="18"/>
<text text-anchor="middle" x="284.6663" y="-157.2">D2H_c</text>
</g>
<g class="m-edge">
<title>p0x7f6fd8000db0&#45;&gt;p0x7f6fd8000ce0</title>
<path d="M284.6663,-215.8314C284.6663,-208.131 284.6663,-198.9743 284.6663,-190.4166"/>
<polygon points="288.1664,-190.4132 284.6663,-180.4133 281.1664,-190.4133 288.1664,-190.4132"/>
</g>
<g class="m-node m-flat">
<title>p0x7f6fd8000c00</title>
<ellipse cx="179.6663" cy="-306" rx="44.2867" ry="18"/>
<text text-anchor="middle" x="179.6663" y="-301.2">H2D_b</text>
</g>
<g class="m-edge">
<title>p0x7f6fd8000c00&#45;&gt;p0x7f6fd8000db0</title>
<path d="M202.4498,-290.3771C216.2921,-280.8852 234.244,-268.5753 249.8402,-257.8808"/>
<polygon points="251.9533,-260.6757 258.2212,-252.1338 247.9946,-254.9025 251.9533,-260.6757"/>
</g>
<g class="m-edge">
<title>p0x7f6fd8000ce0&#45;&gt;p0x5558af971240</title>
<path d="M284.9187,-143.8314C285.0256,-136.131 285.1528,-126.9743 285.2717,-118.4166"/>
<polygon points="288.7713,-118.4609 285.4106,-108.4133 281.772,-118.3637 288.7713,-118.4609"/>
</g>
</g>
</svg>
</div></section><section id="MatrixMultiplicationBenchmarking"><h2><a href="#MatrixMultiplicationBenchmarking">Benchmarking</a></h2><p>We run three versions of matrix multiplication, sequential CPU, parallel CPUs, and one GPU, on a machine of 6 Intel i7-8700 CPUs at 3.20GHz and a Nvidia RTX 2080 GPU using various matrix sizes of A, B, and C.</p><table class="m-table"><thead><tr><th>A</th><th>B</th><th>C</th><th>CPU Sequential</th><th>CPU Parallel</th><th>GPU Parallel</th></tr></thead><tbody><tr><td>10x10</td><td>10x10</td><td>10x10</td><td>0.142 ms</td><td>0.414 ms</td><td>82 ms</td></tr><tr><td>100x100</td><td>100x100</td><td>100x100</td><td>1.641 ms</td><td>0.733 ms</td><td>83 ms</td></tr><tr><td>1000x1000</td><td>1000x1000</td><td>1000x1000</td><td>1532 ms</td><td>504 ms</td><td>85 ms</td></tr><tr><td>2000x2000</td><td>2000x2000</td><td>2000x2000</td><td>25688 ms</td><td>4387 ms</td><td>133 ms</td></tr><tr><td>3000x3000</td><td>3000x3000</td><td>3000x3000</td><td>104838 ms</td><td>16170 ms</td><td>214 ms</td></tr><tr><td>4000x4000</td><td>4000x4000</td><td>4000x4000</td><td>250133 ms</td><td>39646 ms</td><td>427 ms</td></tr></tbody></table><p>With the matrix size going up to 1000, the speed-up of GPU over CPUs becomes prominent.</p></section>
      </div>
    </div>
  </div>
</article></main>
<div class="m-doc-search" id="search">
  <a href="#!" onclick="return hideSearch()"></a>
  <div class="m-container">
    <div class="m-row">
      <div class="m-col-m-8 m-push-m-2">
        <div class="m-doc-search-header m-text m-small">
          <div><span class="m-label m-default">Tab</span> / <span class="m-label m-default">T</span> to search, <span class="m-label m-default">Esc</span> to close</div>
          <div id="search-symbolcount">&hellip;</div>
        </div>
        <div class="m-doc-search-content">
          <form>
            <input type="search" name="q" id="search-input" placeholder="Loading &hellip;" disabled="disabled" autofocus="autofocus" autocomplete="off" spellcheck="false" />
          </form>
          <noscript class="m-text m-danger m-text-center">Unlike everything else in the docs, the search functionality <em>requires</em> JavaScript.</noscript>
          <div id="search-help" class="m-text m-dim m-text-center">
            <p class="m-noindent">Search for symbols, directories, files, pages or
            modules. You can omit any prefix from the symbol or file path; adding a
            <code>:</code> or <code>/</code> suffix lists all members of given symbol or
            directory.</p>
            <p class="m-noindent">Use <span class="m-label m-dim">&darr;</span>
            / <span class="m-label m-dim">&uarr;</span> to navigate through the list,
            <span class="m-label m-dim">Enter</span> to go.
            <span class="m-label m-dim">Tab</span> autocompletes common prefix, you can
            copy a link to the result using <span class="m-label m-dim">⌘</span>
            <span class="m-label m-dim">L</span> while <span class="m-label m-dim">⌘</span>
            <span class="m-label m-dim">M</span> produces a Markdown link.</p>
          </div>
          <div id="search-notfound" class="m-text m-warning m-text-center">Sorry, nothing was found.</div>
          <ul id="search-results"></ul>
        </div>
      </div>
    </div>
  </div>
</div>
<script src="search-v1.js"></script>
<script src="searchdata-v1.js" async="async"></script>
<footer><nav>
  <div class="m-container">
    <div class="m-row">
      <div class="m-col-l-10 m-push-l-1">
        <p>Taskflow handbook is part of the <a href="https://taskflow.github.io">Taskflow project</a>, copyright © <a href="https://tsung-wei-huang.github.io/">Dr. Tsung-Wei Huang</a>, 2018&ndash;2020.<br />Generated by <a href="https://doxygen.org/">Doxygen</a> 1.8.14 and <a href="https://mcss.mosra.cz/">m.css</a>.</p>
      </div>
    </div>
  </div>
</nav></footer>
</body>
</html>
